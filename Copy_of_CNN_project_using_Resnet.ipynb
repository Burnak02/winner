{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Burnak02/winner/blob/master/Copy_of_CNN_project_using_Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXSHXd74oQjT",
        "outputId": "aa9c1b18-5d73-4edb-bf43-523dfb18b933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Qualcomm-DL-Hackathon'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 30.68 MiB | 11.94 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "gQM-NhbAoVHp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "t0hktkcppU9A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_csv = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/train/train.csv\")\n",
        "train_data_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9dT_H4wMpoE-",
        "outputId": "430f1fdc-7ba8-4b8d-8e6e-558339a04114"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  image_names  emergency_or_not\n",
              "0    1503.jpg                 0\n",
              "1    1420.jpg                 0\n",
              "2    1764.jpg                 0\n",
              "3    1356.jpg                 0\n",
              "4    1117.jpg                 0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29137d20-5c9d-4207-b97d-4db4d0e52edb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "      <th>emergency_or_not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1503.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1420.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1764.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1356.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1117.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29137d20-5c9d-4207-b97d-4db4d0e52edb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29137d20-5c9d-4207-b97d-4db4d0e52edb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29137d20-5c9d-4207-b97d-4db4d0e52edb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a0b22b2-3a7a-4786-bc13-15c421c40c31\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a0b22b2-3a7a-4786-bc13-15c421c40c31')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a0b22b2-3a7a-4786-bc13-15c421c40c31 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data_csv",
              "summary": "{\n  \"name\": \"train_data_csv\",\n  \"rows\": 1646,\n  \"fields\": [\n    {\n      \"column\": \"image_names\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1646,\n        \"samples\": [\n          \"242.jpg\",\n          \"1495.jpg\",\n          \"1451.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emergency_or_not\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2tphZBzpsxu",
        "outputId": "7d7c2d00-2a0c-4454-e56c-12562bdfce28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(706, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_dir = \"/content/Train\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "#open and extract the zip file\n",
        "for i in range(1,3):\n",
        "  with zipfile.ZipFile(f\"/content/Qualcomm-DL-Hackathon/train/images part-{i}.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "8reQ9BPjvydP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wvfW0FoxHyZ",
        "outputId": "247d0b28-3b2c-41a2-80c1-22406940fd41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open('/content/Train/images part-1/100.jpg')\n",
        "image.show()"
      ],
      "metadata": {
        "id": "utY3v_JVzxRS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tranformations for the training and test datasets\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
        "\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "jbZyZtw4yZgj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomRotation(20),  # Randomly rotate images by up to 20 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomVerticalFlip(),  # Randomly flip images vertically\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change brightness, contrast, saturation, and hue\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Randomly translate images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "W0Dyxa2gyKji"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_folder = \"/content/Train/final_images\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "  os.makedirs(destination_folder)\n",
        "\n",
        "for i in range(1,3):\n",
        "  source_folder = f\"/content/Train/images part-{i}\"\n",
        "  for root, dirs, files in os.walk(source_folder):\n",
        "    for file in files:\n",
        "      src_file = os.path.join(root, file)\n",
        "      shutil.copy2(src_file, destination_folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "rge5qrTNKsRZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting datasets into train and test\n",
        "test_images = list(test[\"image_names\"])\n",
        "source_folder = f\"/content/Train/final_images\"\n",
        "destination_folder = \"/content/Train/final_test_images\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "  os.makedirs(destination_folder)\n",
        "count = 0\n",
        "for root, dirs, files in os.walk(source_folder):\n",
        "  for file in files:\n",
        "    # if count < 1:\n",
        "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
        "    count += 1\n",
        "    if file in test_images:\n",
        "      # print(\"file\")\n",
        "      src_file = os.path.join(root, file)\n",
        "      # shutil.move(src_file, destination_folder)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CjVZN3rzMW1Q",
        "outputId": "fceccabb-d89f-4f02-e013-42890578a82d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def move_and_delete_files(directory, filenames, dest_folder):\n",
        "    for filename in filenames:\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            shutil.copy2(file_path, dest_folder)\n",
        "            os.remove(file_path)\n",
        "            print(f\"Deleted {file_path}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File {file_path} not found\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "dest_folder = \"/content/test_images\"\n",
        "\n",
        "if not os.path.exists(dest_folder):\n",
        "  os.makedirs(dest_folder)\n",
        "move_and_delete_files(source_folder,test_images,dest_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH5mEnYSrs7v",
        "outputId": "8ec814a2-3388-498d-e746-dccd8fa1f3c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted /content/Train/final_images/1960.jpg\n",
            "Deleted /content/Train/final_images/668.jpg\n",
            "Deleted /content/Train/final_images/2082.jpg\n",
            "Deleted /content/Train/final_images/808.jpg\n",
            "Deleted /content/Train/final_images/1907.jpg\n",
            "Deleted /content/Train/final_images/350.jpg\n",
            "Deleted /content/Train/final_images/1557.jpg\n",
            "Deleted /content/Train/final_images/111.jpg\n",
            "Deleted /content/Train/final_images/1952.jpg\n",
            "Deleted /content/Train/final_images/1466.jpg\n",
            "Deleted /content/Train/final_images/2071.jpg\n",
            "Deleted /content/Train/final_images/1891.jpg\n",
            "Deleted /content/Train/final_images/1900.jpg\n",
            "Deleted /content/Train/final_images/1927.jpg\n",
            "Deleted /content/Train/final_images/1414.jpg\n",
            "Deleted /content/Train/final_images/134.jpg\n",
            "Deleted /content/Train/final_images/1037.jpg\n",
            "Deleted /content/Train/final_images/56.jpg\n",
            "Deleted /content/Train/final_images/208.jpg\n",
            "Deleted /content/Train/final_images/629.jpg\n",
            "Deleted /content/Train/final_images/979.jpg\n",
            "Deleted /content/Train/final_images/2099.jpg\n",
            "Deleted /content/Train/final_images/332.jpg\n",
            "Deleted /content/Train/final_images/1814.jpg\n",
            "Deleted /content/Train/final_images/1094.jpg\n",
            "Deleted /content/Train/final_images/1886.jpg\n",
            "Deleted /content/Train/final_images/342.jpg\n",
            "Deleted /content/Train/final_images/2134.jpg\n",
            "Deleted /content/Train/final_images/1465.jpg\n",
            "Deleted /content/Train/final_images/482.jpg\n",
            "Deleted /content/Train/final_images/229.jpg\n",
            "Deleted /content/Train/final_images/1078.jpg\n",
            "Deleted /content/Train/final_images/611.jpg\n",
            "Deleted /content/Train/final_images/1349.jpg\n",
            "Deleted /content/Train/final_images/1805.jpg\n",
            "Deleted /content/Train/final_images/1947.jpg\n",
            "Deleted /content/Train/final_images/299.jpg\n",
            "Deleted /content/Train/final_images/463.jpg\n",
            "Deleted /content/Train/final_images/2154.jpg\n",
            "Deleted /content/Train/final_images/1244.jpg\n",
            "Deleted /content/Train/final_images/581.jpg\n",
            "Deleted /content/Train/final_images/218.jpg\n",
            "Deleted /content/Train/final_images/1553.jpg\n",
            "Deleted /content/Train/final_images/1025.jpg\n",
            "Deleted /content/Train/final_images/1591.jpg\n",
            "Deleted /content/Train/final_images/1132.jpg\n",
            "Deleted /content/Train/final_images/2117.jpg\n",
            "Deleted /content/Train/final_images/1795.jpg\n",
            "Deleted /content/Train/final_images/2254.jpg\n",
            "Deleted /content/Train/final_images/1950.jpg\n",
            "Deleted /content/Train/final_images/507.jpg\n",
            "Deleted /content/Train/final_images/445.jpg\n",
            "Deleted /content/Train/final_images/1501.jpg\n",
            "Deleted /content/Train/final_images/2349.jpg\n",
            "Deleted /content/Train/final_images/678.jpg\n",
            "Deleted /content/Train/final_images/1604.jpg\n",
            "Deleted /content/Train/final_images/792.jpg\n",
            "Deleted /content/Train/final_images/879.jpg\n",
            "Deleted /content/Train/final_images/1779.jpg\n",
            "Deleted /content/Train/final_images/2156.jpg\n",
            "Deleted /content/Train/final_images/44.jpg\n",
            "Deleted /content/Train/final_images/686.jpg\n",
            "Deleted /content/Train/final_images/1311.jpg\n",
            "Deleted /content/Train/final_images/2192.jpg\n",
            "Deleted /content/Train/final_images/440.jpg\n",
            "Deleted /content/Train/final_images/1047.jpg\n",
            "Deleted /content/Train/final_images/254.jpg\n",
            "Deleted /content/Train/final_images/479.jpg\n",
            "Deleted /content/Train/final_images/282.jpg\n",
            "Deleted /content/Train/final_images/2339.jpg\n",
            "Deleted /content/Train/final_images/2066.jpg\n",
            "Deleted /content/Train/final_images/1379.jpg\n",
            "Deleted /content/Train/final_images/759.jpg\n",
            "Deleted /content/Train/final_images/2262.jpg\n",
            "Deleted /content/Train/final_images/672.jpg\n",
            "Deleted /content/Train/final_images/2036.jpg\n",
            "Deleted /content/Train/final_images/279.jpg\n",
            "Deleted /content/Train/final_images/596.jpg\n",
            "Deleted /content/Train/final_images/486.jpg\n",
            "Deleted /content/Train/final_images/651.jpg\n",
            "Deleted /content/Train/final_images/1138.jpg\n",
            "Deleted /content/Train/final_images/881.jpg\n",
            "Deleted /content/Train/final_images/433.jpg\n",
            "Deleted /content/Train/final_images/1640.jpg\n",
            "Deleted /content/Train/final_images/1293.jpg\n",
            "Deleted /content/Train/final_images/2140.jpg\n",
            "Deleted /content/Train/final_images/2097.jpg\n",
            "Deleted /content/Train/final_images/981.jpg\n",
            "Deleted /content/Train/final_images/1598.jpg\n",
            "Deleted /content/Train/final_images/252.jpg\n",
            "Deleted /content/Train/final_images/1665.jpg\n",
            "Deleted /content/Train/final_images/2259.jpg\n",
            "Deleted /content/Train/final_images/1791.jpg\n",
            "Deleted /content/Train/final_images/869.jpg\n",
            "Deleted /content/Train/final_images/1530.jpg\n",
            "Deleted /content/Train/final_images/1475.jpg\n",
            "Deleted /content/Train/final_images/100.jpg\n",
            "Deleted /content/Train/final_images/2175.jpg\n",
            "Deleted /content/Train/final_images/1714.jpg\n",
            "Deleted /content/Train/final_images/693.jpg\n",
            "Deleted /content/Train/final_images/435.jpg\n",
            "Deleted /content/Train/final_images/2266.jpg\n",
            "Deleted /content/Train/final_images/2227.jpg\n",
            "Deleted /content/Train/final_images/1380.jpg\n",
            "Deleted /content/Train/final_images/430.jpg\n",
            "Deleted /content/Train/final_images/670.jpg\n",
            "Deleted /content/Train/final_images/855.jpg\n",
            "Deleted /content/Train/final_images/1963.jpg\n",
            "Deleted /content/Train/final_images/1377.jpg\n",
            "Deleted /content/Train/final_images/1315.jpg\n",
            "Deleted /content/Train/final_images/1196.jpg\n",
            "Deleted /content/Train/final_images/1237.jpg\n",
            "Deleted /content/Train/final_images/2052.jpg\n",
            "Deleted /content/Train/final_images/1333.jpg\n",
            "Deleted /content/Train/final_images/1198.jpg\n",
            "Deleted /content/Train/final_images/1558.jpg\n",
            "Deleted /content/Train/final_images/849.jpg\n",
            "Deleted /content/Train/final_images/237.jpg\n",
            "Deleted /content/Train/final_images/432.jpg\n",
            "Deleted /content/Train/final_images/1673.jpg\n",
            "Deleted /content/Train/final_images/529.jpg\n",
            "Deleted /content/Train/final_images/1847.jpg\n",
            "Deleted /content/Train/final_images/1827.jpg\n",
            "Deleted /content/Train/final_images/2298.jpg\n",
            "Deleted /content/Train/final_images/1279.jpg\n",
            "Deleted /content/Train/final_images/2174.jpg\n",
            "Deleted /content/Train/final_images/809.jpg\n",
            "Deleted /content/Train/final_images/1780.jpg\n",
            "Deleted /content/Train/final_images/926.jpg\n",
            "Deleted /content/Train/final_images/196.jpg\n",
            "Deleted /content/Train/final_images/810.jpg\n",
            "Deleted /content/Train/final_images/29.jpg\n",
            "Deleted /content/Train/final_images/461.jpg\n",
            "Deleted /content/Train/final_images/1211.jpg\n",
            "Deleted /content/Train/final_images/973.jpg\n",
            "Deleted /content/Train/final_images/179.jpg\n",
            "Deleted /content/Train/final_images/367.jpg\n",
            "Deleted /content/Train/final_images/548.jpg\n",
            "Deleted /content/Train/final_images/1395.jpg\n",
            "Deleted /content/Train/final_images/368.jpg\n",
            "Deleted /content/Train/final_images/2126.jpg\n",
            "Deleted /content/Train/final_images/422.jpg\n",
            "Deleted /content/Train/final_images/1965.jpg\n",
            "Deleted /content/Train/final_images/173.jpg\n",
            "Deleted /content/Train/final_images/1594.jpg\n",
            "Deleted /content/Train/final_images/471.jpg\n",
            "Deleted /content/Train/final_images/892.jpg\n",
            "Deleted /content/Train/final_images/478.jpg\n",
            "Deleted /content/Train/final_images/2257.jpg\n",
            "Deleted /content/Train/final_images/602.jpg\n",
            "Deleted /content/Train/final_images/1767.jpg\n",
            "Deleted /content/Train/final_images/1340.jpg\n",
            "Deleted /content/Train/final_images/69.jpg\n",
            "Deleted /content/Train/final_images/2265.jpg\n",
            "Deleted /content/Train/final_images/426.jpg\n",
            "Deleted /content/Train/final_images/1338.jpg\n",
            "Deleted /content/Train/final_images/1828.jpg\n",
            "Deleted /content/Train/final_images/485.jpg\n",
            "Deleted /content/Train/final_images/96.jpg\n",
            "Deleted /content/Train/final_images/247.jpg\n",
            "Deleted /content/Train/final_images/2118.jpg\n",
            "Deleted /content/Train/final_images/2272.jpg\n",
            "Deleted /content/Train/final_images/383.jpg\n",
            "Deleted /content/Train/final_images/472.jpg\n",
            "Deleted /content/Train/final_images/210.jpg\n",
            "Deleted /content/Train/final_images/937.jpg\n",
            "Deleted /content/Train/final_images/1966.jpg\n",
            "Deleted /content/Train/final_images/2098.jpg\n",
            "Deleted /content/Train/final_images/1584.jpg\n",
            "Deleted /content/Train/final_images/1513.jpg\n",
            "Deleted /content/Train/final_images/1538.jpg\n",
            "Deleted /content/Train/final_images/1292.jpg\n",
            "Deleted /content/Train/final_images/1970.jpg\n",
            "Deleted /content/Train/final_images/1418.jpg\n",
            "Deleted /content/Train/final_images/1444.jpg\n",
            "Deleted /content/Train/final_images/480.jpg\n",
            "Deleted /content/Train/final_images/1288.jpg\n",
            "Deleted /content/Train/final_images/2248.jpg\n",
            "Deleted /content/Train/final_images/495.jpg\n",
            "Deleted /content/Train/final_images/1668.jpg\n",
            "Deleted /content/Train/final_images/527.jpg\n",
            "Deleted /content/Train/final_images/2155.jpg\n",
            "Deleted /content/Train/final_images/1885.jpg\n",
            "Deleted /content/Train/final_images/1523.jpg\n",
            "Deleted /content/Train/final_images/2144.jpg\n",
            "Deleted /content/Train/final_images/2189.jpg\n",
            "Deleted /content/Train/final_images/1968.jpg\n",
            "Deleted /content/Train/final_images/1216.jpg\n",
            "Deleted /content/Train/final_images/211.jpg\n",
            "Deleted /content/Train/final_images/321.jpg\n",
            "Deleted /content/Train/final_images/695.jpg\n",
            "Deleted /content/Train/final_images/1436.jpg\n",
            "Deleted /content/Train/final_images/361.jpg\n",
            "Deleted /content/Train/final_images/873.jpg\n",
            "Deleted /content/Train/final_images/259.jpg\n",
            "Deleted /content/Train/final_images/1690.jpg\n",
            "Deleted /content/Train/final_images/948.jpg\n",
            "Deleted /content/Train/final_images/2343.jpg\n",
            "Deleted /content/Train/final_images/2278.jpg\n",
            "Deleted /content/Train/final_images/1204.jpg\n",
            "Deleted /content/Train/final_images/1359.jpg\n",
            "Deleted /content/Train/final_images/1967.jpg\n",
            "Deleted /content/Train/final_images/1105.jpg\n",
            "Deleted /content/Train/final_images/1207.jpg\n",
            "Deleted /content/Train/final_images/1737.jpg\n",
            "Deleted /content/Train/final_images/2073.jpg\n",
            "Deleted /content/Train/final_images/1904.jpg\n",
            "Deleted /content/Train/final_images/408.jpg\n",
            "Deleted /content/Train/final_images/2129.jpg\n",
            "Deleted /content/Train/final_images/508.jpg\n",
            "Deleted /content/Train/final_images/67.jpg\n",
            "Deleted /content/Train/final_images/807.jpg\n",
            "Deleted /content/Train/final_images/1736.jpg\n",
            "Deleted /content/Train/final_images/1406.jpg\n",
            "Deleted /content/Train/final_images/48.jpg\n",
            "Deleted /content/Train/final_images/544.jpg\n",
            "Deleted /content/Train/final_images/509.jpg\n",
            "Deleted /content/Train/final_images/1273.jpg\n",
            "Deleted /content/Train/final_images/251.jpg\n",
            "Deleted /content/Train/final_images/1703.jpg\n",
            "Deleted /content/Train/final_images/416.jpg\n",
            "Deleted /content/Train/final_images/1357.jpg\n",
            "Deleted /content/Train/final_images/1645.jpg\n",
            "Deleted /content/Train/final_images/1163.jpg\n",
            "Deleted /content/Train/final_images/1263.jpg\n",
            "Deleted /content/Train/final_images/618.jpg\n",
            "Deleted /content/Train/final_images/450.jpg\n",
            "Deleted /content/Train/final_images/1264.jpg\n",
            "Deleted /content/Train/final_images/1320.jpg\n",
            "Deleted /content/Train/final_images/859.jpg\n",
            "Deleted /content/Train/final_images/291.jpg\n",
            "Deleted /content/Train/final_images/1798.jpg\n",
            "Deleted /content/Train/final_images/2311.jpg\n",
            "Deleted /content/Train/final_images/1223.jpg\n",
            "Deleted /content/Train/final_images/998.jpg\n",
            "Deleted /content/Train/final_images/2181.jpg\n",
            "Deleted /content/Train/final_images/817.jpg\n",
            "Deleted /content/Train/final_images/296.jpg\n",
            "Deleted /content/Train/final_images/1364.jpg\n",
            "Deleted /content/Train/final_images/410.jpg\n",
            "Deleted /content/Train/final_images/1004.jpg\n",
            "Deleted /content/Train/final_images/528.jpg\n",
            "Deleted /content/Train/final_images/1303.jpg\n",
            "Deleted /content/Train/final_images/1382.jpg\n",
            "Deleted /content/Train/final_images/637.jpg\n",
            "Deleted /content/Train/final_images/767.jpg\n",
            "Deleted /content/Train/final_images/1811.jpg\n",
            "Deleted /content/Train/final_images/2059.jpg\n",
            "Deleted /content/Train/final_images/1928.jpg\n",
            "Deleted /content/Train/final_images/2168.jpg\n",
            "Deleted /content/Train/final_images/188.jpg\n",
            "Deleted /content/Train/final_images/786.jpg\n",
            "Deleted /content/Train/final_images/240.jpg\n",
            "Deleted /content/Train/final_images/1455.jpg\n",
            "Deleted /content/Train/final_images/1085.jpg\n",
            "Deleted /content/Train/final_images/70.jpg\n",
            "Deleted /content/Train/final_images/2107.jpg\n",
            "Deleted /content/Train/final_images/1985.jpg\n",
            "Deleted /content/Train/final_images/73.jpg\n",
            "Deleted /content/Train/final_images/1655.jpg\n",
            "Deleted /content/Train/final_images/829.jpg\n",
            "Deleted /content/Train/final_images/1385.jpg\n",
            "Deleted /content/Train/final_images/1525.jpg\n",
            "Deleted /content/Train/final_images/1979.jpg\n",
            "Deleted /content/Train/final_images/1271.jpg\n",
            "Deleted /content/Train/final_images/157.jpg\n",
            "Deleted /content/Train/final_images/565.jpg\n",
            "Deleted /content/Train/final_images/1807.jpg\n",
            "Deleted /content/Train/final_images/838.jpg\n",
            "Deleted /content/Train/final_images/407.jpg\n",
            "Deleted /content/Train/final_images/2287.jpg\n",
            "Deleted /content/Train/final_images/2230.jpg\n",
            "Deleted /content/Train/final_images/927.jpg\n",
            "Deleted /content/Train/final_images/51.jpg\n",
            "Deleted /content/Train/final_images/1910.jpg\n",
            "Deleted /content/Train/final_images/915.jpg\n",
            "Deleted /content/Train/final_images/1222.jpg\n",
            "Deleted /content/Train/final_images/1694.jpg\n",
            "Deleted /content/Train/final_images/1861.jpg\n",
            "Deleted /content/Train/final_images/1607.jpg\n",
            "Deleted /content/Train/final_images/1064.jpg\n",
            "Deleted /content/Train/final_images/1268.jpg\n",
            "Deleted /content/Train/final_images/1511.jpg\n",
            "Deleted /content/Train/final_images/630.jpg\n",
            "Deleted /content/Train/final_images/1750.jpg\n",
            "Deleted /content/Train/final_images/831.jpg\n",
            "Deleted /content/Train/final_images/1605.jpg\n",
            "Deleted /content/Train/final_images/610.jpg\n",
            "Deleted /content/Train/final_images/1713.jpg\n",
            "Deleted /content/Train/final_images/220.jpg\n",
            "Deleted /content/Train/final_images/1151.jpg\n",
            "Deleted /content/Train/final_images/2002.jpg\n",
            "Deleted /content/Train/final_images/84.jpg\n",
            "Deleted /content/Train/final_images/1463.jpg\n",
            "Deleted /content/Train/final_images/2078.jpg\n",
            "Deleted /content/Train/final_images/109.jpg\n",
            "Deleted /content/Train/final_images/2335.jpg\n",
            "Deleted /content/Train/final_images/420.jpg\n",
            "Deleted /content/Train/final_images/290.jpg\n",
            "Deleted /content/Train/final_images/694.jpg\n",
            "Deleted /content/Train/final_images/861.jpg\n",
            "Deleted /content/Train/final_images/867.jpg\n",
            "Deleted /content/Train/final_images/617.jpg\n",
            "Deleted /content/Train/final_images/1100.jpg\n",
            "Deleted /content/Train/final_images/2277.jpg\n",
            "Deleted /content/Train/final_images/1842.jpg\n",
            "Deleted /content/Train/final_images/212.jpg\n",
            "Deleted /content/Train/final_images/1776.jpg\n",
            "Deleted /content/Train/final_images/1976.jpg\n",
            "Deleted /content/Train/final_images/1835.jpg\n",
            "Deleted /content/Train/final_images/719.jpg\n",
            "Deleted /content/Train/final_images/18.jpg\n",
            "Deleted /content/Train/final_images/2219.jpg\n",
            "Deleted /content/Train/final_images/1398.jpg\n",
            "Deleted /content/Train/final_images/1719.jpg\n",
            "Deleted /content/Train/final_images/1662.jpg\n",
            "Deleted /content/Train/final_images/1055.jpg\n",
            "Deleted /content/Train/final_images/76.jpg\n",
            "Deleted /content/Train/final_images/952.jpg\n",
            "Deleted /content/Train/final_images/1902.jpg\n",
            "Deleted /content/Train/final_images/2008.jpg\n",
            "Deleted /content/Train/final_images/819.jpg\n",
            "Deleted /content/Train/final_images/798.jpg\n",
            "Deleted /content/Train/final_images/168.jpg\n",
            "Deleted /content/Train/final_images/387.jpg\n",
            "Deleted /content/Train/final_images/1170.jpg\n",
            "Deleted /content/Train/final_images/1187.jpg\n",
            "Deleted /content/Train/final_images/2208.jpg\n",
            "Deleted /content/Train/final_images/219.jpg\n",
            "Deleted /content/Train/final_images/990.jpg\n",
            "Deleted /content/Train/final_images/1441.jpg\n",
            "Deleted /content/Train/final_images/303.jpg\n",
            "Deleted /content/Train/final_images/2337.jpg\n",
            "Deleted /content/Train/final_images/1653.jpg\n",
            "Deleted /content/Train/final_images/438.jpg\n",
            "Deleted /content/Train/final_images/530.jpg\n",
            "Deleted /content/Train/final_images/1639.jpg\n",
            "Deleted /content/Train/final_images/1423.jpg\n",
            "Deleted /content/Train/final_images/2276.jpg\n",
            "Deleted /content/Train/final_images/1112.jpg\n",
            "Deleted /content/Train/final_images/1817.jpg\n",
            "Deleted /content/Train/final_images/231.jpg\n",
            "Deleted /content/Train/final_images/1606.jpg\n",
            "Deleted /content/Train/final_images/135.jpg\n",
            "Deleted /content/Train/final_images/25.jpg\n",
            "Deleted /content/Train/final_images/1195.jpg\n",
            "Deleted /content/Train/final_images/765.jpg\n",
            "Deleted /content/Train/final_images/1868.jpg\n",
            "Deleted /content/Train/final_images/1454.jpg\n",
            "Deleted /content/Train/final_images/903.jpg\n",
            "Deleted /content/Train/final_images/192.jpg\n",
            "Deleted /content/Train/final_images/289.jpg\n",
            "Deleted /content/Train/final_images/414.jpg\n",
            "Deleted /content/Train/final_images/1552.jpg\n",
            "Deleted /content/Train/final_images/1316.jpg\n",
            "Deleted /content/Train/final_images/930.jpg\n",
            "Deleted /content/Train/final_images/1729.jpg\n",
            "Deleted /content/Train/final_images/1987.jpg\n",
            "Deleted /content/Train/final_images/128.jpg\n",
            "Deleted /content/Train/final_images/1940.jpg\n",
            "Deleted /content/Train/final_images/886.jpg\n",
            "Deleted /content/Train/final_images/233.jpg\n",
            "Deleted /content/Train/final_images/1728.jpg\n",
            "Deleted /content/Train/final_images/307.jpg\n",
            "Deleted /content/Train/final_images/1743.jpg\n",
            "Deleted /content/Train/final_images/613.jpg\n",
            "Deleted /content/Train/final_images/2021.jpg\n",
            "Deleted /content/Train/final_images/874.jpg\n",
            "Deleted /content/Train/final_images/2178.jpg\n",
            "Deleted /content/Train/final_images/177.jpg\n",
            "Deleted /content/Train/final_images/2271.jpg\n",
            "Deleted /content/Train/final_images/2225.jpg\n",
            "Deleted /content/Train/final_images/1789.jpg\n",
            "Deleted /content/Train/final_images/184.jpg\n",
            "Deleted /content/Train/final_images/1864.jpg\n",
            "Deleted /content/Train/final_images/1310.jpg\n",
            "Deleted /content/Train/final_images/2152.jpg\n",
            "Deleted /content/Train/final_images/1521.jpg\n",
            "Deleted /content/Train/final_images/298.jpg\n",
            "Deleted /content/Train/final_images/402.jpg\n",
            "Deleted /content/Train/final_images/1029.jpg\n",
            "Deleted /content/Train/final_images/575.jpg\n",
            "Deleted /content/Train/final_images/2089.jpg\n",
            "Deleted /content/Train/final_images/2309.jpg\n",
            "Deleted /content/Train/final_images/800.jpg\n",
            "Deleted /content/Train/final_images/1611.jpg\n",
            "Deleted /content/Train/final_images/178.jpg\n",
            "Deleted /content/Train/final_images/1334.jpg\n",
            "Deleted /content/Train/final_images/1667.jpg\n",
            "Deleted /content/Train/final_images/727.jpg\n",
            "Deleted /content/Train/final_images/2033.jpg\n",
            "Deleted /content/Train/final_images/1897.jpg\n",
            "Deleted /content/Train/final_images/522.jpg\n",
            "Deleted /content/Train/final_images/118.jpg\n",
            "Deleted /content/Train/final_images/464.jpg\n",
            "Deleted /content/Train/final_images/1360.jpg\n",
            "Deleted /content/Train/final_images/2147.jpg\n",
            "Deleted /content/Train/final_images/511.jpg\n",
            "Deleted /content/Train/final_images/1964.jpg\n",
            "Deleted /content/Train/final_images/2233.jpg\n",
            "Deleted /content/Train/final_images/2111.jpg\n",
            "Deleted /content/Train/final_images/555.jpg\n",
            "Deleted /content/Train/final_images/1249.jpg\n",
            "Deleted /content/Train/final_images/906.jpg\n",
            "Deleted /content/Train/final_images/620.jpg\n",
            "Deleted /content/Train/final_images/621.jpg\n",
            "Deleted /content/Train/final_images/366.jpg\n",
            "Deleted /content/Train/final_images/1261.jpg\n",
            "Deleted /content/Train/final_images/1278.jpg\n",
            "Deleted /content/Train/final_images/1936.jpg\n",
            "Deleted /content/Train/final_images/677.jpg\n",
            "Deleted /content/Train/final_images/944.jpg\n",
            "Deleted /content/Train/final_images/1121.jpg\n",
            "Deleted /content/Train/final_images/203.jpg\n",
            "Deleted /content/Train/final_images/174.jpg\n",
            "Deleted /content/Train/final_images/2045.jpg\n",
            "Deleted /content/Train/final_images/120.jpg\n",
            "Deleted /content/Train/final_images/283.jpg\n",
            "Deleted /content/Train/final_images/976.jpg\n",
            "Deleted /content/Train/final_images/598.jpg\n",
            "Deleted /content/Train/final_images/1732.jpg\n",
            "Deleted /content/Train/final_images/2201.jpg\n",
            "Deleted /content/Train/final_images/1178.jpg\n",
            "Deleted /content/Train/final_images/554.jpg\n",
            "Deleted /content/Train/final_images/275.jpg\n",
            "Deleted /content/Train/final_images/2282.jpg\n",
            "Deleted /content/Train/final_images/636.jpg\n",
            "Deleted /content/Train/final_images/360.jpg\n",
            "Deleted /content/Train/final_images/1391.jpg\n",
            "Deleted /content/Train/final_images/1602.jpg\n",
            "Deleted /content/Train/final_images/964.jpg\n",
            "Deleted /content/Train/final_images/605.jpg\n",
            "Deleted /content/Train/final_images/1697.jpg\n",
            "Deleted /content/Train/final_images/1050.jpg\n",
            "Deleted /content/Train/final_images/1393.jpg\n",
            "Deleted /content/Train/final_images/787.jpg\n",
            "Deleted /content/Train/final_images/1344.jpg\n",
            "Deleted /content/Train/final_images/599.jpg\n",
            "Deleted /content/Train/final_images/286.jpg\n",
            "Deleted /content/Train/final_images/2194.jpg\n",
            "Deleted /content/Train/final_images/406.jpg\n",
            "Deleted /content/Train/final_images/1487.jpg\n",
            "Deleted /content/Train/final_images/163.jpg\n",
            "Deleted /content/Train/final_images/1609.jpg\n",
            "Deleted /content/Train/final_images/423.jpg\n",
            "Deleted /content/Train/final_images/2261.jpg\n",
            "Deleted /content/Train/final_images/1128.jpg\n",
            "Deleted /content/Train/final_images/632.jpg\n",
            "Deleted /content/Train/final_images/1883.jpg\n",
            "Deleted /content/Train/final_images/1430.jpg\n",
            "Deleted /content/Train/final_images/1651.jpg\n",
            "Deleted /content/Train/final_images/2267.jpg\n",
            "Deleted /content/Train/final_images/1269.jpg\n",
            "Deleted /content/Train/final_images/700.jpg\n",
            "Deleted /content/Train/final_images/457.jpg\n",
            "Deleted /content/Train/final_images/650.jpg\n",
            "Deleted /content/Train/final_images/900.jpg\n",
            "Deleted /content/Train/final_images/230.jpg\n",
            "Deleted /content/Train/final_images/1962.jpg\n",
            "Deleted /content/Train/final_images/1084.jpg\n",
            "Deleted /content/Train/final_images/1318.jpg\n",
            "Deleted /content/Train/final_images/1744.jpg\n",
            "Deleted /content/Train/final_images/1725.jpg\n",
            "Deleted /content/Train/final_images/1068.jpg\n",
            "Deleted /content/Train/final_images/733.jpg\n",
            "Deleted /content/Train/final_images/324.jpg\n",
            "Deleted /content/Train/final_images/2243.jpg\n",
            "Deleted /content/Train/final_images/374.jpg\n",
            "Deleted /content/Train/final_images/834.jpg\n",
            "Deleted /content/Train/final_images/1330.jpg\n",
            "Deleted /content/Train/final_images/2010.jpg\n",
            "Deleted /content/Train/final_images/564.jpg\n",
            "Deleted /content/Train/final_images/297.jpg\n",
            "Deleted /content/Train/final_images/932.jpg\n",
            "Deleted /content/Train/final_images/239.jpg\n",
            "Deleted /content/Train/final_images/99.jpg\n",
            "Deleted /content/Train/final_images/1461.jpg\n",
            "Deleted /content/Train/final_images/281.jpg\n",
            "Deleted /content/Train/final_images/354.jpg\n",
            "Deleted /content/Train/final_images/1313.jpg\n",
            "Deleted /content/Train/final_images/2063.jpg\n",
            "Deleted /content/Train/final_images/642.jpg\n",
            "Deleted /content/Train/final_images/1284.jpg\n",
            "Deleted /content/Train/final_images/1229.jpg\n",
            "Deleted /content/Train/final_images/1080.jpg\n",
            "Deleted /content/Train/final_images/923.jpg\n",
            "Deleted /content/Train/final_images/1875.jpg\n",
            "Deleted /content/Train/final_images/124.jpg\n",
            "Deleted /content/Train/final_images/2317.jpg\n",
            "Deleted /content/Train/final_images/185.jpg\n",
            "Deleted /content/Train/final_images/2158.jpg\n",
            "Deleted /content/Train/final_images/532.jpg\n",
            "Deleted /content/Train/final_images/857.jpg\n",
            "Deleted /content/Train/final_images/1366.jpg\n",
            "Deleted /content/Train/final_images/2023.jpg\n",
            "Deleted /content/Train/final_images/1577.jpg\n",
            "Deleted /content/Train/final_images/2092.jpg\n",
            "Deleted /content/Train/final_images/1403.jpg\n",
            "Deleted /content/Train/final_images/65.jpg\n",
            "Deleted /content/Train/final_images/1266.jpg\n",
            "Deleted /content/Train/final_images/353.jpg\n",
            "Deleted /content/Train/final_images/643.jpg\n",
            "Deleted /content/Train/final_images/2226.jpg\n",
            "Deleted /content/Train/final_images/1499.jpg\n",
            "Deleted /content/Train/final_images/1608.jpg\n",
            "Deleted /content/Train/final_images/1127.jpg\n",
            "Deleted /content/Train/final_images/1232.jpg\n",
            "Deleted /content/Train/final_images/1783.jpg\n",
            "Deleted /content/Train/final_images/49.jpg\n",
            "Deleted /content/Train/final_images/1646.jpg\n",
            "Deleted /content/Train/final_images/2030.jpg\n",
            "Deleted /content/Train/final_images/925.jpg\n",
            "Deleted /content/Train/final_images/840.jpg\n",
            "Deleted /content/Train/final_images/1381.jpg\n",
            "Deleted /content/Train/final_images/2143.jpg\n",
            "Deleted /content/Train/final_images/23.jpg\n",
            "Deleted /content/Train/final_images/929.jpg\n",
            "Deleted /content/Train/final_images/785.jpg\n",
            "Deleted /content/Train/final_images/1102.jpg\n",
            "Deleted /content/Train/final_images/2247.jpg\n",
            "Deleted /content/Train/final_images/1993.jpg\n",
            "Deleted /content/Train/final_images/1740.jpg\n",
            "Deleted /content/Train/final_images/2245.jpg\n",
            "Deleted /content/Train/final_images/1087.jpg\n",
            "Deleted /content/Train/final_images/311.jpg\n",
            "Deleted /content/Train/final_images/351.jpg\n",
            "Deleted /content/Train/final_images/306.jpg\n",
            "Deleted /content/Train/final_images/961.jpg\n",
            "Deleted /content/Train/final_images/1034.jpg\n",
            "Deleted /content/Train/final_images/2162.jpg\n",
            "Deleted /content/Train/final_images/1681.jpg\n",
            "Deleted /content/Train/final_images/756.jpg\n",
            "Deleted /content/Train/final_images/1137.jpg\n",
            "Deleted /content/Train/final_images/1583.jpg\n",
            "Deleted /content/Train/final_images/1621.jpg\n",
            "Deleted /content/Train/final_images/1706.jpg\n",
            "Deleted /content/Train/final_images/986.jpg\n",
            "Deleted /content/Train/final_images/13.jpg\n",
            "Deleted /content/Train/final_images/1945.jpg\n",
            "Deleted /content/Train/final_images/514.jpg\n",
            "Deleted /content/Train/final_images/409.jpg\n",
            "Deleted /content/Train/final_images/788.jpg\n",
            "Deleted /content/Train/final_images/2040.jpg\n",
            "Deleted /content/Train/final_images/1637.jpg\n",
            "Deleted /content/Train/final_images/949.jpg\n",
            "Deleted /content/Train/final_images/729.jpg\n",
            "Deleted /content/Train/final_images/647.jpg\n",
            "Deleted /content/Train/final_images/1944.jpg\n",
            "Deleted /content/Train/final_images/382.jpg\n",
            "Deleted /content/Train/final_images/821.jpg\n",
            "Deleted /content/Train/final_images/1411.jpg\n",
            "Deleted /content/Train/final_images/1287.jpg\n",
            "Deleted /content/Train/final_images/1017.jpg\n",
            "Deleted /content/Train/final_images/1924.jpg\n",
            "Deleted /content/Train/final_images/2274.jpg\n",
            "Deleted /content/Train/final_images/2007.jpg\n",
            "Deleted /content/Train/final_images/582.jpg\n",
            "Deleted /content/Train/final_images/1053.jpg\n",
            "Deleted /content/Train/final_images/705.jpg\n",
            "Deleted /content/Train/final_images/1192.jpg\n",
            "Deleted /content/Train/final_images/1873.jpg\n",
            "Deleted /content/Train/final_images/8.jpg\n",
            "Deleted /content/Train/final_images/316.jpg\n",
            "Deleted /content/Train/final_images/2037.jpg\n",
            "Deleted /content/Train/final_images/427.jpg\n",
            "Deleted /content/Train/final_images/105.jpg\n",
            "Deleted /content/Train/final_images/1301.jpg\n",
            "Deleted /content/Train/final_images/121.jpg\n",
            "Deleted /content/Train/final_images/1352.jpg\n",
            "Deleted /content/Train/final_images/2186.jpg\n",
            "Deleted /content/Train/final_images/2275.jpg\n",
            "Deleted /content/Train/final_images/1724.jpg\n",
            "Deleted /content/Train/final_images/115.jpg\n",
            "Deleted /content/Train/final_images/1532.jpg\n",
            "Deleted /content/Train/final_images/2195.jpg\n",
            "Deleted /content/Train/final_images/685.jpg\n",
            "Deleted /content/Train/final_images/746.jpg\n",
            "Deleted /content/Train/final_images/2293.jpg\n",
            "Deleted /content/Train/final_images/2051.jpg\n",
            "Deleted /content/Train/final_images/782.jpg\n",
            "Deleted /content/Train/final_images/1247.jpg\n",
            "Deleted /content/Train/final_images/742.jpg\n",
            "Deleted /content/Train/final_images/552.jpg\n",
            "Deleted /content/Train/final_images/87.jpg\n",
            "Deleted /content/Train/final_images/1472.jpg\n",
            "Deleted /content/Train/final_images/2270.jpg\n",
            "Deleted /content/Train/final_images/1405.jpg\n",
            "Deleted /content/Train/final_images/1001.jpg\n",
            "Deleted /content/Train/final_images/1547.jpg\n",
            "Deleted /content/Train/final_images/1918.jpg\n",
            "Deleted /content/Train/final_images/543.jpg\n",
            "Deleted /content/Train/final_images/1535.jpg\n",
            "Deleted /content/Train/final_images/494.jpg\n",
            "Deleted /content/Train/final_images/1146.jpg\n",
            "Deleted /content/Train/final_images/2128.jpg\n",
            "Deleted /content/Train/final_images/1747.jpg\n",
            "Deleted /content/Train/final_images/1720.jpg\n",
            "Deleted /content/Train/final_images/71.jpg\n",
            "Deleted /content/Train/final_images/63.jpg\n",
            "Deleted /content/Train/final_images/1220.jpg\n",
            "Deleted /content/Train/final_images/1255.jpg\n",
            "Deleted /content/Train/final_images/845.jpg\n",
            "Deleted /content/Train/final_images/1199.jpg\n",
            "Deleted /content/Train/final_images/1760.jpg\n",
            "Deleted /content/Train/final_images/1125.jpg\n",
            "Deleted /content/Train/final_images/1670.jpg\n",
            "Deleted /content/Train/final_images/1537.jpg\n",
            "Deleted /content/Train/final_images/931.jpg\n",
            "Deleted /content/Train/final_images/1341.jpg\n",
            "Deleted /content/Train/final_images/205.jpg\n",
            "Deleted /content/Train/final_images/841.jpg\n",
            "Deleted /content/Train/final_images/1990.jpg\n",
            "Deleted /content/Train/final_images/557.jpg\n",
            "Deleted /content/Train/final_images/377.jpg\n",
            "Deleted /content/Train/final_images/535.jpg\n",
            "Deleted /content/Train/final_images/1131.jpg\n",
            "Deleted /content/Train/final_images/1456.jpg\n",
            "Deleted /content/Train/final_images/198.jpg\n",
            "Deleted /content/Train/final_images/561.jpg\n",
            "Deleted /content/Train/final_images/1061.jpg\n",
            "Deleted /content/Train/final_images/590.jpg\n",
            "Deleted /content/Train/final_images/519.jpg\n",
            "Deleted /content/Train/final_images/308.jpg\n",
            "Deleted /content/Train/final_images/1876.jpg\n",
            "Deleted /content/Train/final_images/2229.jpg\n",
            "Deleted /content/Train/final_images/59.jpg\n",
            "Deleted /content/Train/final_images/836.jpg\n",
            "Deleted /content/Train/final_images/2318.jpg\n",
            "Deleted /content/Train/final_images/207.jpg\n",
            "Deleted /content/Train/final_images/1949.jpg\n",
            "Deleted /content/Train/final_images/1351.jpg\n",
            "Deleted /content/Train/final_images/1488.jpg\n",
            "Deleted /content/Train/final_images/162.jpg\n",
            "Deleted /content/Train/final_images/1270.jpg\n",
            "Deleted /content/Train/final_images/1745.jpg\n",
            "Deleted /content/Train/final_images/1033.jpg\n",
            "Deleted /content/Train/final_images/256.jpg\n",
            "Deleted /content/Train/final_images/506.jpg\n",
            "Deleted /content/Train/final_images/1717.jpg\n",
            "Deleted /content/Train/final_images/1946.jpg\n",
            "Deleted /content/Train/final_images/649.jpg\n",
            "Deleted /content/Train/final_images/1457.jpg\n",
            "Deleted /content/Train/final_images/20.jpg\n",
            "Deleted /content/Train/final_images/1647.jpg\n",
            "Deleted /content/Train/final_images/1177.jpg\n",
            "Deleted /content/Train/final_images/381.jpg\n",
            "Deleted /content/Train/final_images/538.jpg\n",
            "Deleted /content/Train/final_images/862.jpg\n",
            "Deleted /content/Train/final_images/679.jpg\n",
            "Deleted /content/Train/final_images/83.jpg\n",
            "Deleted /content/Train/final_images/2159.jpg\n",
            "Deleted /content/Train/final_images/1179.jpg\n",
            "Deleted /content/Train/final_images/1281.jpg\n",
            "Deleted /content/Train/final_images/270.jpg\n",
            "Deleted /content/Train/final_images/889.jpg\n",
            "Deleted /content/Train/final_images/965.jpg\n",
            "Deleted /content/Train/final_images/1772.jpg\n",
            "Deleted /content/Train/final_images/888.jpg\n",
            "Deleted /content/Train/final_images/1110.jpg\n",
            "Deleted /content/Train/final_images/1848.jpg\n",
            "Deleted /content/Train/final_images/429.jpg\n",
            "Deleted /content/Train/final_images/1894.jpg\n",
            "Deleted /content/Train/final_images/963.jpg\n",
            "Deleted /content/Train/final_images/2039.jpg\n",
            "Deleted /content/Train/final_images/458.jpg\n",
            "Deleted /content/Train/final_images/78.jpg\n",
            "Deleted /content/Train/final_images/2091.jpg\n",
            "Deleted /content/Train/final_images/32.jpg\n",
            "Deleted /content/Train/final_images/916.jpg\n",
            "Deleted /content/Train/final_images/1644.jpg\n",
            "Deleted /content/Train/final_images/2113.jpg\n",
            "Deleted /content/Train/final_images/380.jpg\n",
            "Deleted /content/Train/final_images/226.jpg\n",
            "Deleted /content/Train/final_images/1208.jpg\n",
            "Deleted /content/Train/final_images/1321.jpg\n",
            "Deleted /content/Train/final_images/305.jpg\n",
            "Deleted /content/Train/final_images/209.jpg\n",
            "Deleted /content/Train/final_images/1143.jpg\n",
            "Deleted /content/Train/final_images/1452.jpg\n",
            "Deleted /content/Train/final_images/2331.jpg\n",
            "Deleted /content/Train/final_images/1491.jpg\n",
            "Deleted /content/Train/final_images/715.jpg\n",
            "Deleted /content/Train/final_images/707.jpg\n",
            "Deleted /content/Train/final_images/1852.jpg\n",
            "Deleted /content/Train/final_images/1000.jpg\n",
            "Deleted /content/Train/final_images/2312.jpg\n",
            "Deleted /content/Train/final_images/483.jpg\n",
            "Deleted /content/Train/final_images/2206.jpg\n",
            "Deleted /content/Train/final_images/277.jpg\n",
            "Deleted /content/Train/final_images/2338.jpg\n",
            "Deleted /content/Train/final_images/221.jpg\n",
            "Deleted /content/Train/final_images/1459.jpg\n",
            "Deleted /content/Train/final_images/571.jpg\n",
            "Deleted /content/Train/final_images/411.jpg\n",
            "Deleted /content/Train/final_images/1089.jpg\n",
            "Deleted /content/Train/final_images/1103.jpg\n",
            "Deleted /content/Train/final_images/585.jpg\n",
            "Deleted /content/Train/final_images/1054.jpg\n",
            "Deleted /content/Train/final_images/1502.jpg\n",
            "Deleted /content/Train/final_images/2345.jpg\n",
            "Deleted /content/Train/final_images/1362.jpg\n",
            "Deleted /content/Train/final_images/674.jpg\n",
            "Deleted /content/Train/final_images/1027.jpg\n",
            "Deleted /content/Train/final_images/447.jpg\n",
            "Deleted /content/Train/final_images/2176.jpg\n",
            "Deleted /content/Train/final_images/1014.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "res = {\"image_names\":[], \"emergency_or_not\":[]}\n",
        "for root, dirs, files in os.walk(dest_folder):\n",
        "  for file in files:\n",
        "    # if count < 1:\n",
        "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
        "    count += 1\n",
        "    res[\"image_names\"].append(file)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGjVovTRLxqP",
        "outputId": "40f815e5-369b-4f9c-c8d0-617ee993c582"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomImageDatasetWithLabels(Dataset):\n",
        "    def __init__(self, csv_file, image_folder, transform=None):\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.labels_df.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        label = int(self.labels_df.iloc[idx, 1])  # Convert label to int\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "7Q9RSylOsgZ6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paths to your CSV files and image folders\n",
        "train_csv = '/content/Qualcomm-DL-Hackathon/train/train.csv'\n",
        "train_image_folder = '/content/Train/final_images'\n",
        "\n",
        "# Initialize your datasets\n",
        "train_dataset = CustomImageDatasetWithLabels(csv_file=train_csv, image_folder=train_image_folder, transform=train_transforms)\n",
        "\n"
      ],
      "metadata": {
        "id": "rR7Suqv_s0_J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_size = int(0.8 * len(train_dataset))\n",
        "# test_size = len(train_dataset) - train_size\n",
        "# train_data, test_data = random_split(train_dataset, [train_size, test_size])\n",
        "\n",
        "class CustomImageDatasetWithoutLabels(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_names = os.listdir(image_folder)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.image_names[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# Initialize your test dataset\n",
        "test_dataset = CustomImageDatasetWithoutLabels(image_folder=dest_folder, transform=test_transforms)\n"
      ],
      "metadata": {
        "id": "_ldNB0ZTtKYu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "hlupPVNBtYOS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    labels_list = labels.tolist()  # Convert tensor to list of integers\n",
        "    print(len(labels_list))  # This will print a list of 0s and 1s\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1PKagpJtbKb",
        "outputId": "c0d3ef33-c4f3-4b37-bde3-117e56c598c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "# # conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "# # conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "# # pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "# # fc1 = nn.Linear(128 * 16 * 16, 512)\n",
        "# # fc2 = nn.Linear(512, 2)\n",
        "# # dropout = nn.Dropout(0.5)\n",
        "\n",
        "# # filter size = 5 and additional layers\n",
        "# #Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: 89.09%\n",
        "# conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "# bn1 = nn.BatchNorm2d(32)\n",
        "# conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "# bn2 = nn.BatchNorm2d(64)\n",
        "# conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)\n",
        "# bn3 = nn.BatchNorm2d(128)\n",
        "# conv4 = nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2)\n",
        "# bn4 = nn.BatchNorm2d(256)\n",
        "# pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "# fc1 = nn.Linear(256 * 8 * 8, 512)\n",
        "# fc2 = nn.Linear(512, 2)\n",
        "# dropout = nn.Dropout(0.3)\n",
        "\n",
        "conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "bn1 = nn.BatchNorm2d(32)\n",
        "conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "bn2 = nn.BatchNorm2d(64)\n",
        "conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)\n",
        "bn3 = nn.BatchNorm2d(128)\n",
        "conv4 = nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2)\n",
        "bn4 = nn.BatchNorm2d(256)\n",
        "pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "fc1 = nn.Linear(256 * 8 * 8, 128)\n",
        "fc2 = nn.Linear(128, 128)\n",
        "fc3 = nn.Linear(128, 2)\n",
        "dropout = nn.Dropout(0.3)\n"
      ],
      "metadata": {
        "id": "2a1Nk1lQvshz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    conv1,\n",
        "    bn1,\n",
        "    nn.ReLU(),\n",
        "    pool,\n",
        "    conv2,\n",
        "    bn2,\n",
        "    nn.ReLU(),\n",
        "    pool,\n",
        "    conv3,\n",
        "    bn3,\n",
        "    nn.ReLU(),\n",
        "    pool,\n",
        "    conv4,\n",
        "    bn4,\n",
        "    nn.ReLU(),\n",
        "    pool,\n",
        "    nn.Flatten(),\n",
        "    fc1,\n",
        "    nn.ReLU(),\n",
        "    dropout,\n",
        "    fc2,\n",
        "    nn.ReLU(),\n",
        "    dropout,\n",
        "    fc3\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "Ala0H8cjwMw8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "model = resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs,2)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "4B4ipU6y2G1w",
        "outputId": "f299ede2-64ac-4b57-986b-e8ff152de1e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 209MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# scheduler = StepLR(optimizer, step_size=20, gamma=0.1)"
      ],
      "metadata": {
        "id": "Vwjwdx0-wo6J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "    # scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SLFs7ewwvYR",
        "outputId": "1fa5ed42-34c0-4e14-f6e0-624c136973c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 0.8346, Accuracy: 54.92%\n",
            "Epoch 2/30, Loss: 0.6680, Accuracy: 61.73%\n",
            "Epoch 3/30, Loss: 0.6052, Accuracy: 66.40%\n",
            "Epoch 4/30, Loss: 0.5753, Accuracy: 72.11%\n",
            "Epoch 5/30, Loss: 0.6078, Accuracy: 68.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.eval()\n",
        "# test_correct = 0\n",
        "# test_total = 0\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in test_loader:\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "#         outputs = model(inputs)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         test_total += labels.size(0)\n",
        "#         test_correct += (predicted == labels).sum().item()\n",
        "# test_accuracy = 100 * test_correct / test_total\n",
        "# print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "res[\"emergency_or_not\"].clear()\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print([t.item() for t in list(predicted)])\n",
        "        res[\"emergency_or_not\"].extend([t.item() for t in list(predicted)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSvDowBdxRiI",
        "outputId": "ce87f14b-adcf-4159-80ee-6ad5cb7b79ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "[1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
            "[0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1]\n",
            "[1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
            "[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
            "[0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]\n",
            "[0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "[1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
            "[0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n",
            "[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "[1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]\n",
            "[0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "[1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(res[\"emergency_or_not\"]), len(res[\"image_names\"]))\n",
        "results = {}\n",
        "for i in range(len(res[\"image_names\"])):\n",
        "  results[res[\"image_names\"][i]] = res[\"emergency_or_not\"][i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTtYj13zRd_M",
        "outputId": "580f05ff-f0fd-4ea6-f479-7cd549cee239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706 706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = []\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
        "for i in list(data[\"image_names\"]):\n",
        "  temp.append(results[i])\n",
        "data[\"emergency_or_not\"] = temp\n",
        "data.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "E86akeorSQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning the hyperparameters\n",
        "\n",
        "learning_rates = [0.001, 0.01]\n",
        "batch_sizes = [16,32]\n",
        "dropout_rates = [0.3, 0.5]\n",
        "hidden_layers = [1,2,3]\n",
        "hidden_units = [128,128]\n",
        "num_epochs = 10\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for dropout_rate in dropout_rates:\n",
        "            for num_hidden_layers in hidden_layers:\n",
        "                for hidden_units_per_layer in hidden_units:\n",
        "\n",
        "                    # Recreate data loaders with the current batch size\n",
        "                    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "                    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                    # Define the CNN model arch with the current number of hidden layers and dropout rate\n",
        "                    conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "                    conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "                    conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "                    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "                    fc_layers = []\n",
        "\n",
        "                    # Create hidden layers based on the number of hidden layers\n",
        "\n",
        "                    input_size = 256 * 8 * 8\n",
        "                    for i in range(num_hidden_layers):\n",
        "                        fc_layers.append(nn.Linear(input_size, hidden_units_per_layer))\n",
        "                        fc_layers.append(nn.ReLU())\n",
        "                        fc_layers.append(nn.Dropout(dropout_rate))\n",
        "                        input_size = hidden_units_per_layer\n",
        "\n",
        "                    fc_layers.append(nn.Linear(input_size, 2))\n",
        "                    model = nn.Sequential(\n",
        "                        conv1,\n",
        "                        bn1,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        conv2,\n",
        "                        bn2,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        conv3,\n",
        "                        bn3,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        conv4,\n",
        "                        bn4,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        nn.Flatten(),\n",
        "                        *fc_layers\n",
        "                    ).to(device)\n",
        "\n",
        "                    #Define the loss function and optimizer for this combination of hyperparameters\n",
        "                    criterion = nn.CrossEntropyLoss()\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                    # Train the model\n",
        "                    for epoch in range(num_epochs):\n",
        "                      model.train()\n",
        "                      running_loss = 0.0\n",
        "                      correct = 0\n",
        "                      total = 0\n",
        "\n",
        "                      for inputs, labels in train_loader:\n",
        "                          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                          optimizer.zero_grad()\n",
        "                          outputs = model(inputs)\n",
        "                          loss = criterion(outputs, labels)\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                          running_loss += loss.item()\n",
        "                          _,predicted = torch.max(outputs.data,1)\n",
        "                          total += labels.size(0)\n",
        "                          correct += (predicted == labels).sum().item()\n",
        "\n",
        "                      epoch_loss = running_loss / len(train_loader)\n",
        "                      epoch_acc = 100 * correct / total\n",
        "                      print(f\"Epoch [{epoch+1}/{num_epochs}] for lr={lr}, batch_size={batch_size}, dropout={dropout_rate}, hidden_layers={num_hidden_layers}, hidden_units={hidden_units_per_layer}: Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "\n",
        "                    # Evaluate on the validation set after training\n",
        "                    model.eval()\n",
        "                    test_correct = 0\n",
        "                    test_total = 0\n",
        "                    with torch.no_grad():\n",
        "                      for inputs, labels in test_loader:\n",
        "                          inputs, labels = inputs.to(device), labels.to(device)\n",
        "                          outputs  = model(inputs)\n",
        "                          _,predicted = torch.max(outputs.data,1)\n",
        "                          test_total += labels.size(0)\n",
        "                          test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    test_accuracy = 100 * test_correct / test_total\n",
        "                    print(f\"Validation accuracy for lr={lr}, batch_size={batch_size}, dropout={dropout_rate}, hidden_layers={num_hidden_layers}, hidden_units={hidden_units_per_layer}: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1oUtduigYOd",
        "outputId": "2a1077bb-1ad6-4b18-8c95-3ccdf7afd884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.9132, Accuracy: 63.75%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.5955, Accuracy: 69.76%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.5601, Accuracy: 71.28%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4962, Accuracy: 76.37%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4309, Accuracy: 80.85%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3973, Accuracy: 81.84%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3862, Accuracy: 84.50%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3576, Accuracy: 85.18%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3405, Accuracy: 87.01%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3144, Accuracy: 88.30%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: 80.00%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6771, Accuracy: 73.18%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4344, Accuracy: 81.16%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3856, Accuracy: 81.61%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3268, Accuracy: 85.79%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2847, Accuracy: 88.30%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2584, Accuracy: 89.82%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2382, Accuracy: 90.20%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1924, Accuracy: 92.63%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1463, Accuracy: 95.21%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1395, Accuracy: 94.83%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: 76.67%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6638, Accuracy: 64.97%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4929, Accuracy: 77.51%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4416, Accuracy: 79.94%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3863, Accuracy: 82.45%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3604, Accuracy: 86.93%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3333, Accuracy: 86.85%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2618, Accuracy: 89.97%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2177, Accuracy: 91.34%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1914, Accuracy: 92.48%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1669, Accuracy: 93.77%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: 88.18%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.5709, Accuracy: 72.95%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4241, Accuracy: 80.02%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3245, Accuracy: 86.40%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2646, Accuracy: 89.13%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2226, Accuracy: 90.81%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1952, Accuracy: 91.95%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1840, Accuracy: 93.09%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1170, Accuracy: 95.82%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1103, Accuracy: 95.82%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1067, Accuracy: 96.12%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: 85.45%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5374, Accuracy: 73.10%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.3634, Accuracy: 84.80%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.2915, Accuracy: 87.01%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.2445, Accuracy: 90.81%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.2050, Accuracy: 91.19%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.1464, Accuracy: 95.21%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.1341, Accuracy: 95.14%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0945, Accuracy: 96.43%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0580, Accuracy: 98.40%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0832, Accuracy: 97.80%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: 86.06%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5059, Accuracy: 75.23%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.3660, Accuracy: 84.73%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.2248, Accuracy: 90.81%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.1523, Accuracy: 94.45%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.1210, Accuracy: 94.98%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0693, Accuracy: 97.42%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0506, Accuracy: 98.48%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0496, Accuracy: 98.40%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0471, Accuracy: 98.71%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0456, Accuracy: 98.10%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: 83.03%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4772, Accuracy: 76.37%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3213, Accuracy: 86.09%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.1907, Accuracy: 92.71%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.1199, Accuracy: 95.59%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0910, Accuracy: 97.42%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0652, Accuracy: 97.80%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0437, Accuracy: 98.25%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0545, Accuracy: 98.25%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0695, Accuracy: 97.57%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0456, Accuracy: 98.33%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: 86.97%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4705, Accuracy: 77.66%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.2939, Accuracy: 87.92%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.1476, Accuracy: 93.84%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0850, Accuracy: 96.81%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0832, Accuracy: 96.88%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0537, Accuracy: 98.25%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0368, Accuracy: 98.56%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0178, Accuracy: 99.62%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0204, Accuracy: 99.47%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0343, Accuracy: 98.94%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: 85.15%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5803, Accuracy: 69.07%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4108, Accuracy: 81.08%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.3052, Accuracy: 87.61%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.2416, Accuracy: 90.50%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1742, Accuracy: 93.39%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1241, Accuracy: 95.36%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0530, Accuracy: 98.18%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0984, Accuracy: 96.50%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0487, Accuracy: 98.86%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0999, Accuracy: 96.43%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: 84.55%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5210, Accuracy: 72.19%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.3132, Accuracy: 88.60%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.2026, Accuracy: 92.25%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1126, Accuracy: 96.12%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0691, Accuracy: 97.42%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0722, Accuracy: 97.80%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0573, Accuracy: 98.02%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0698, Accuracy: 99.24%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0395, Accuracy: 98.78%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0284, Accuracy: 99.32%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: 87.88%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5618, Accuracy: 68.92%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.3568, Accuracy: 85.03%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.2326, Accuracy: 91.34%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1347, Accuracy: 95.36%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0966, Accuracy: 97.04%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0673, Accuracy: 97.72%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0500, Accuracy: 98.40%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0579, Accuracy: 97.57%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0499, Accuracy: 98.48%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0687, Accuracy: 97.95%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: 84.24%\n",
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5825, Accuracy: 63.91%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.4099, Accuracy: 81.84%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.2932, Accuracy: 89.36%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1876, Accuracy: 93.24%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1227, Accuracy: 95.90%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0901, Accuracy: 97.34%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0501, Accuracy: 98.25%\n",
            "Epoch [8/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0759, Accuracy: 97.95%\n",
            "Epoch [9/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0410, Accuracy: 98.86%\n",
            "Epoch [10/10] for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0227, Accuracy: 99.54%\n",
            "Validation accuracy for lr=0.001, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: 81.52%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.5245, Accuracy: 75.30%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3226, Accuracy: 86.09%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2155, Accuracy: 91.34%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1165, Accuracy: 95.82%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0655, Accuracy: 97.95%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0338, Accuracy: 99.01%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0226, Accuracy: 99.32%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0182, Accuracy: 99.54%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0399, Accuracy: 98.86%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0888, Accuracy: 96.58%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: 85.15%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4315, Accuracy: 80.78%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2258, Accuracy: 91.19%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0999, Accuracy: 96.58%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0580, Accuracy: 98.25%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0474, Accuracy: 98.18%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0254, Accuracy: 99.01%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0215, Accuracy: 99.47%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0125, Accuracy: 99.62%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0061, Accuracy: 99.85%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.0146, Accuracy: 99.85%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: 86.36%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4657, Accuracy: 78.57%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2700, Accuracy: 88.60%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1367, Accuracy: 95.36%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1166, Accuracy: 95.21%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0457, Accuracy: 98.18%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0249, Accuracy: 99.16%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0149, Accuracy: 99.54%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0086, Accuracy: 99.77%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0652, Accuracy: 98.02%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0398, Accuracy: 99.16%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: 89.09%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4806, Accuracy: 75.68%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2344, Accuracy: 90.96%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.1006, Accuracy: 96.58%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0434, Accuracy: 98.56%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0409, Accuracy: 99.01%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0261, Accuracy: 99.16%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0351, Accuracy: 99.01%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0125, Accuracy: 99.39%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0107, Accuracy: 99.47%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.0099, Accuracy: 99.54%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: 86.36%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.4930, Accuracy: 74.09%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.2205, Accuracy: 90.73%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0906, Accuracy: 96.88%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0961, Accuracy: 96.96%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0170, Accuracy: 99.54%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0280, Accuracy: 98.86%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0141, Accuracy: 99.39%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0191, Accuracy: 99.47%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0382, Accuracy: 98.56%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0163, Accuracy: 99.16%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: 84.24%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5045, Accuracy: 74.77%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.2541, Accuracy: 89.13%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.1010, Accuracy: 96.88%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0614, Accuracy: 97.95%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0290, Accuracy: 99.01%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0728, Accuracy: 97.57%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0306, Accuracy: 98.94%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0248, Accuracy: 99.24%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0134, Accuracy: 99.62%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.0232, Accuracy: 99.24%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: 79.39%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4208, Accuracy: 80.24%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.1597, Accuracy: 94.22%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0579, Accuracy: 97.95%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0231, Accuracy: 99.32%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0152, Accuracy: 99.70%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0119, Accuracy: 99.77%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0070, Accuracy: 99.70%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0096, Accuracy: 99.77%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0311, Accuracy: 99.09%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0566, Accuracy: 97.95%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: 87.27%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4984, Accuracy: 76.90%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.2680, Accuracy: 88.75%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.1086, Accuracy: 96.66%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0317, Accuracy: 99.47%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0201, Accuracy: 99.47%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0100, Accuracy: 99.70%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0152, Accuracy: 99.70%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0062, Accuracy: 99.77%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0042, Accuracy: 99.85%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.0061, Accuracy: 99.77%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: 87.27%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5275, Accuracy: 71.73%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.2743, Accuracy: 88.07%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1210, Accuracy: 95.97%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0724, Accuracy: 97.49%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0532, Accuracy: 98.56%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0307, Accuracy: 99.09%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0084, Accuracy: 99.77%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0372, Accuracy: 99.77%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1909, Accuracy: 93.54%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0247, Accuracy: 99.32%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: 85.45%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4766, Accuracy: 77.05%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.2562, Accuracy: 89.36%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1268, Accuracy: 96.35%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1076, Accuracy: 96.88%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.1392, Accuracy: 94.68%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0267, Accuracy: 99.24%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0301, Accuracy: 99.85%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0300, Accuracy: 99.32%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0180, Accuracy: 99.54%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.0059, Accuracy: 99.85%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: 86.36%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6199, Accuracy: 60.56%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.4395, Accuracy: 79.71%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.2669, Accuracy: 88.83%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1138, Accuracy: 96.35%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0631, Accuracy: 97.87%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0524, Accuracy: 98.25%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0795, Accuracy: 97.87%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0640, Accuracy: 98.10%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0263, Accuracy: 99.09%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0302, Accuracy: 99.24%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: 84.85%\n",
            "Epoch [1/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6335, Accuracy: 59.04%\n",
            "Epoch [2/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5070, Accuracy: 77.20%\n",
            "Epoch [3/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.3637, Accuracy: 86.17%\n",
            "Epoch [4/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.3152, Accuracy: 87.31%\n",
            "Epoch [5/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1977, Accuracy: 92.40%\n",
            "Epoch [6/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1437, Accuracy: 93.84%\n",
            "Epoch [7/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0807, Accuracy: 97.04%\n",
            "Epoch [8/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0760, Accuracy: 98.25%\n",
            "Epoch [9/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.1163, Accuracy: 96.12%\n",
            "Epoch [10/10] for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.0605, Accuracy: 98.02%\n",
            "Validation accuracy for lr=0.001, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: 86.06%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.5660, Accuracy: 71.66%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4444, Accuracy: 79.56%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3612, Accuracy: 83.89%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3122, Accuracy: 88.68%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2765, Accuracy: 89.13%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1829, Accuracy: 92.71%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1928, Accuracy: 92.71%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1668, Accuracy: 94.38%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1202, Accuracy: 96.05%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1379, Accuracy: 94.76%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: 81.82%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6237, Accuracy: 67.63%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.5642, Accuracy: 75.00%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.5013, Accuracy: 77.51%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4342, Accuracy: 79.64%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4177, Accuracy: 81.84%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3691, Accuracy: 83.89%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3061, Accuracy: 86.63%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2798, Accuracy: 88.98%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2536, Accuracy: 88.98%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2159, Accuracy: 91.11%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: 80.61%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.5937, Accuracy: 68.16%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.5152, Accuracy: 76.60%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4589, Accuracy: 79.41%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4220, Accuracy: 81.16%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3728, Accuracy: 83.36%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3324, Accuracy: 86.70%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3794, Accuracy: 84.73%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3022, Accuracy: 87.46%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2839, Accuracy: 88.53%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2411, Accuracy: 88.98%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: 82.73%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6282, Accuracy: 67.02%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.5592, Accuracy: 73.71%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4844, Accuracy: 77.05%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4163, Accuracy: 80.70%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.4125, Accuracy: 81.38%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3747, Accuracy: 83.13%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3826, Accuracy: 81.61%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.3208, Accuracy: 85.87%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2863, Accuracy: 88.60%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.2568, Accuracy: 89.44%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=2, hidden_units=128: 77.27%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5991, Accuracy: 69.53%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5085, Accuracy: 76.60%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.4945, Accuracy: 76.29%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.4525, Accuracy: 80.78%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.4437, Accuracy: 81.16%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.4027, Accuracy: 82.60%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.4478, Accuracy: 80.24%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.3966, Accuracy: 82.37%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.3545, Accuracy: 84.73%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.3557, Accuracy: 84.57%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: 78.48%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6644, Accuracy: 63.15%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6253, Accuracy: 65.35%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6130, Accuracy: 64.51%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5613, Accuracy: 71.81%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5438, Accuracy: 71.66%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5759, Accuracy: 72.04%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5502, Accuracy: 73.48%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5700, Accuracy: 73.40%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5515, Accuracy: 71.81%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.5076, Accuracy: 76.60%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.3, hidden_layers=3, hidden_units=128: 69.39%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6533, Accuracy: 59.35%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.5965, Accuracy: 69.53%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4995, Accuracy: 75.00%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.5092, Accuracy: 76.60%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4634, Accuracy: 77.96%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4194, Accuracy: 80.85%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4065, Accuracy: 81.69%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3893, Accuracy: 81.00%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3622, Accuracy: 83.51%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3409, Accuracy: 85.18%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: 77.58%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6251, Accuracy: 64.29%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.5593, Accuracy: 72.72%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.5093, Accuracy: 75.61%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4783, Accuracy: 78.04%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4242, Accuracy: 80.47%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4084, Accuracy: 81.46%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3702, Accuracy: 83.89%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3490, Accuracy: 83.43%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3212, Accuracy: 86.63%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.2924, Accuracy: 87.99%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=1, hidden_units=128: 81.21%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6701, Accuracy: 59.73%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6410, Accuracy: 64.21%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6426, Accuracy: 61.63%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6501, Accuracy: 65.20%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6102, Accuracy: 69.53%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6435, Accuracy: 71.05%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5815, Accuracy: 71.58%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5627, Accuracy: 73.33%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5486, Accuracy: 74.09%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5513, Accuracy: 73.02%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: 78.48%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6425, Accuracy: 63.30%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5693, Accuracy: 71.66%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5482, Accuracy: 72.80%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5089, Accuracy: 76.52%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5309, Accuracy: 75.99%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4916, Accuracy: 75.84%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4556, Accuracy: 78.88%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4968, Accuracy: 76.52%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4582, Accuracy: 77.58%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4333, Accuracy: 78.57%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=2, hidden_units=128: 77.27%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6662, Accuracy: 58.28%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6588, Accuracy: 60.41%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6793, Accuracy: 59.04%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6771, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6758, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6756, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6758, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6763, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6761, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6815, Accuracy: 59.65%\n",
            "Epoch [2/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6779, Accuracy: 59.50%\n",
            "Epoch [3/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6752, Accuracy: 59.19%\n",
            "Epoch [4/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6749, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6756, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6746, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6761, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6742, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6762, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=16, dropout=0.5, hidden_layers=3, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6778, Accuracy: 59.65%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6748, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6772, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6725, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6779, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6760, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6756, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6734, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6759, Accuracy: 59.19%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6750, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6747, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6713, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6774, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6759, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6785, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6729, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6733, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6746, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=1, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6792, Accuracy: 58.66%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6730, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6776, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6733, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6809, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6754, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6784, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6756, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6772, Accuracy: 59.65%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6756, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6766, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6776, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6709, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6762, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6781, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6747, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6716, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: Loss: 0.6770, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=2, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6790, Accuracy: 59.57%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6787, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6749, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6763, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6742, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6777, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6757, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6778, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6753, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6778, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6771, Accuracy: 59.65%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6736, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6770, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6739, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6755, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6763, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6745, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6759, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6758, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: Loss: 0.6778, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.3, hidden_layers=3, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6766, Accuracy: 59.04%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6825, Accuracy: 59.65%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6748, Accuracy: 59.65%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6729, Accuracy: 59.65%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6804, Accuracy: 59.65%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6759, Accuracy: 59.65%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6772, Accuracy: 59.65%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6802, Accuracy: 59.65%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6706, Accuracy: 59.65%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6756, Accuracy: 59.65%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: 54.55%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6766, Accuracy: 60.11%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.6474, Accuracy: 66.41%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.5976, Accuracy: 71.43%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.5215, Accuracy: 76.29%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4636, Accuracy: 79.26%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4403, Accuracy: 80.78%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3918, Accuracy: 82.45%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.4093, Accuracy: 83.43%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3401, Accuracy: 86.02%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: Loss: 0.3753, Accuracy: 85.03%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=1, hidden_units=128: 80.00%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6459, Accuracy: 62.16%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5864, Accuracy: 70.52%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5289, Accuracy: 73.25%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5880, Accuracy: 67.40%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5326, Accuracy: 73.48%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4899, Accuracy: 77.20%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4677, Accuracy: 78.95%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4953, Accuracy: 76.90%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4310, Accuracy: 81.08%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.4390, Accuracy: 80.78%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: 75.76%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6668, Accuracy: 59.42%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6533, Accuracy: 61.09%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6519, Accuracy: 60.94%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6438, Accuracy: 60.56%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.6233, Accuracy: 63.53%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5866, Accuracy: 70.14%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5825, Accuracy: 69.38%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5774, Accuracy: 72.49%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5272, Accuracy: 74.16%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: Loss: 0.5147, Accuracy: 76.82%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=2, hidden_units=128: 71.82%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6881, Accuracy: 56.69%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6678, Accuracy: 58.97%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6475, Accuracy: 63.15%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6090, Accuracy: 65.58%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5766, Accuracy: 68.92%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6012, Accuracy: 64.06%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5839, Accuracy: 67.17%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5949, Accuracy: 67.17%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5471, Accuracy: 70.59%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5405, Accuracy: 70.44%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: 62.12%\n",
            "Epoch [1/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6625, Accuracy: 60.87%\n",
            "Epoch [2/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6236, Accuracy: 71.43%\n",
            "Epoch [3/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5705, Accuracy: 73.33%\n",
            "Epoch [4/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.6028, Accuracy: 71.12%\n",
            "Epoch [5/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5524, Accuracy: 73.48%\n",
            "Epoch [6/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5875, Accuracy: 73.86%\n",
            "Epoch [7/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5413, Accuracy: 73.86%\n",
            "Epoch [8/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5660, Accuracy: 73.18%\n",
            "Epoch [9/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5642, Accuracy: 74.24%\n",
            "Epoch [10/10] for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: Loss: 0.5249, Accuracy: 75.08%\n",
            "Validation accuracy for lr=0.01, batch_size=32, dropout=0.5, hidden_layers=3, hidden_units=128: 72.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning the hyperparameters\n",
        "\n",
        "learning_rates = [0.001, 0.01]\n",
        "batch_sizes = [16,32]\n",
        "dropout_rates = [0.3, 0.5]\n",
        "hidden_layers = [1,2,3]\n",
        "hidden_units = [128,128]\n",
        "num_epochs = 10\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for dropout_rate in dropout_rates:\n",
        "            for num_hidden_layers in hidden_layers:\n",
        "                for hidden_units_per_layer in hidden_units:\n",
        "\n",
        "                    # Recreate data loaders with the current batch size\n",
        "                    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "                    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                    # Define the CNN model arch with the current number of hidden layers and dropout rate\n",
        "                    conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "                    conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "                    conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "                    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "                    fc_layers = []\n",
        "\n",
        "                    # Create hidden layers based on the number of hidden layers\n",
        "\n",
        "                    input_size = 128 * 16 * 16\n",
        "                    for i in range(num_hidden_layers):\n",
        "                        fc_layers.append(nn.Linear(input_size, hidden_units_per_layer))\n",
        "                        fc_layers.append(nn.ReLU())\n",
        "                        fc_layers.append(nn.Dropout(dropout_rate))\n",
        "                        input_size = hidden_units_per_layer\n",
        "\n",
        "                    fc_layers.append(nn.Linear(input_size, 2))\n",
        "                    model = nn.Sequential(\n",
        "                        conv1,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        conv2,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        conv3,\n",
        "                        nn.ReLU(),\n",
        "                        pool,\n",
        "                        nn.Flatten(),\n",
        "                        *fc_layers\n",
        "                    ).to(device)\n",
        "\n",
        "                    #Define the loss function and optimizer for this combination of hyperparameters\n",
        "                    criterion = nn.CrossEntropyLoss()\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                    # Train the model\n",
        "                    for epoch in range(num_epochs):\n",
        "                      model.train()\n",
        "                      running_loss = 0.0\n",
        "                      correct = 0\n",
        "                      total = 0\n",
        "\n",
        "                      for inputs, labels in train_loader:\n",
        "                          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                          optimizer.zero_grad()\n",
        "                          outputs = model(inputs)\n",
        "                          loss = criterion(outputs, labels)\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                          running_loss += loss.item()\n",
        "                          _,predicted = torch.max(outputs.data,1)\n",
        "                          total += labels.size(0)\n",
        "                          correct += (predicted == labels).sum().item()\n",
        "\n",
        "                      epoch_loss = running_loss / len(train_loader)\n",
        "                      epoch_acc = 100 * correct / total\n",
        "                      print(f\"Epoch [{epoch+1}/{num_epochs}] for lr={lr}, batch_size={batch_size}, dropout={dropout_rate}, hidden_layers={num_hidden_layers}, hidden_units={hidden_units_per_layer}: Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "\n",
        "                    # Evaluate on the validation set after training\n",
        "                    model.eval()\n",
        "                    test_correct = 0\n",
        "                    test_total = 0\n",
        "                    with torch.no_grad():\n",
        "                      for inputs, labels in test_loader:\n",
        "                          inputs, labels = inputs.to(device), labels.to(device)\n",
        "                          outputs  = model(inputs)\n",
        "                          _,predicted = torch.max(outputs.data,1)\n",
        "                          test_total += labels.size(0)\n",
        "                          test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    test_accuracy = 100 * test_correct / test_total\n",
        "                    print(f\"Validation accuracy for lr={lr}, batch_size={batch_size}, dropout={dropout_rate}, hidden_layers={num_hidden_layers}, hidden_units={hidden_units_per_layer}: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "khgPDLgsxuhJ",
        "outputId": "bd29c0e7-f3e8-428e-86cd-3b2d9c8d4c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.6310, Accuracy: 67.17%\n",
            "Epoch [2/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4959, Accuracy: 78.04%\n",
            "Epoch [3/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.4076, Accuracy: 81.46%\n",
            "Epoch [4/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.3521, Accuracy: 83.89%\n",
            "Epoch [5/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.2817, Accuracy: 88.22%\n",
            "Epoch [6/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1887, Accuracy: 92.63%\n",
            "Epoch [7/10] for lr=0.001, batch_size=16, dropout=0.3, hidden_layers=1, hidden_units=128: Loss: 0.1303, Accuracy: 95.06%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-9fefb285ec06>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m                           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                           \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Data augmentation with resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# import torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "\n",
        "#Define the data augmentation transform and normalization\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.486, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.486, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#Define the model\n",
        "\n",
        "model = resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    _,predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  epoch_loss = running_loss / len(train_loader)\n",
        "  epoch_acc = 100 * correct / total\n",
        "  print(f\"Epoch [{epoch+1}/{epochs}] Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "toatl = 0\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test accuracy {test_accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FA3aN4sGJSMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c51c52d-f27d-483a-fc9f-671662445432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 202MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.4806, Accuracy: 81.31%\n",
            "Epoch [2/10] Loss: 0.1970, Accuracy: 93.31%\n",
            "Epoch [3/10] Loss: 0.1840, Accuracy: 92.78%\n",
            "Epoch [4/10] Loss: 0.1012, Accuracy: 96.81%\n",
            "Epoch [5/10] Loss: 0.0954, Accuracy: 96.12%\n",
            "Epoch [6/10] Loss: 0.0568, Accuracy: 98.18%\n",
            "Epoch [7/10] Loss: 0.1697, Accuracy: 93.09%\n",
            "Epoch [8/10] Loss: 0.0541, Accuracy: 97.64%\n",
            "Epoch [9/10] Loss: 0.0267, Accuracy: 99.01%\n",
            "Epoch [10/10] Loss: 0.0712, Accuracy: 99.54%\n",
            "Test accuracy 16.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-nDIqI3YoVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}