{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7UlbYJaSIeO",
    "outputId": "752ede87-cad4-431e-fdf7-bb1f0ba241b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "#import torch libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NhhI4TLSoxh",
    "outputId": "3d095f41-afa0-4a65-814d-fb6cea84bafc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Qualcomm-DL-Hackathon'...\n",
      "remote: Enumerating objects: 10, done.\u001b[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (10/10), 30.68 MiB | 14.90 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "# clone the repo\n",
    "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RJ9QYzaSSsV9"
   },
   "outputs": [],
   "source": [
    "# extract the content\n",
    "extract_dir = \"/content/Train\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "#open and extract the zip file\n",
    "for i in range(1,3):\n",
    "  with zipfile.ZipFile(f\"/content/Qualcomm-DL-Hackathon/train/images part-{i}.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KjanpXuTTON-"
   },
   "outputs": [],
   "source": [
    "train_data_csv = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/train/train.csv\")\n",
    "test = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JZrjbCXGS24H"
   },
   "outputs": [],
   "source": [
    "# extract images and split them into train and test\n",
    "\n",
    "destination_folder = \"/content/Train/train_images\"\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "  os.makedirs(destination_folder)\n",
    "\n",
    "for i in range(1,3):\n",
    "  source_folder = f\"/content/Train/images part-{i}\"\n",
    "  for root, dirs, files in os.walk(source_folder):\n",
    "    for file in files:\n",
    "      src_file = os.path.join(root, file)\n",
    "      shutil.copy2(src_file, destination_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbKZpbUGTI_G",
    "outputId": "4a565f62-15b9-46c6-f5b1-38814e2ca922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352\n"
     ]
    }
   ],
   "source": [
    "#splitting datasets into train and test\n",
    "test_images = list(test[\"image_names\"])\n",
    "source_folder = f\"/content/Train/train_images\"\n",
    "destination_folder = \"/content/Train/final_test_images\"\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "  os.makedirs(destination_folder)\n",
    "count = 0\n",
    "for root, dirs, files in os.walk(source_folder):\n",
    "  for file in files:\n",
    "    # if count < 1:\n",
    "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
    "    count += 1\n",
    "    if file in test_images:\n",
    "      # print(\"file\")\n",
    "      src_file = os.path.join(root, file)\n",
    "      shutil.move(src_file, destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L26HTJhdTdn1",
    "outputId": "ca29ee79-90b2-4795-ecdb-56e1802e0b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n"
     ]
    }
   ],
   "source": [
    "# initialize the res dict to construct final csv at the end\n",
    "count = 0\n",
    "res = {\"image_names\":[], \"emergency_or_not\":[]}\n",
    "for root, dirs, files in os.walk(destination_folder):\n",
    "  for file in files:\n",
    "    # if count < 1:\n",
    "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
    "    count += 1\n",
    "    res[\"image_names\"].append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c_DlI-7ATtQd"
   },
   "outputs": [],
   "source": [
    "# Creating classes to handle image to label mapping with(for train) and without labels(for test)\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDatasetWithLabels(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.labels_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label = int(self.labels_df.iloc[idx, 1])  # Convert label to int\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "class CustomImageDatasetWithoutLabels(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_names = os.listdir(image_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_names[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XEiDiMhKALr_"
   },
   "outputs": [],
   "source": [
    "# Tried different combinations with color saturation, vertical flip, etc. \n",
    "# Found this combination to be better than others\n",
    "# Here, we resize the image to 256x256 along with horizontal flip and rotation of 15 degrees.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KwhUtoO1U9H1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Paths to your CSV files and image folders\n",
    "train_csv = '/content/Qualcomm-DL-Hackathon/train/train.csv'\n",
    "train_image_folder = '/content/Train/train_images'\n",
    "\n",
    "# Initialize your datasets\n",
    "train_dataset = CustomImageDatasetWithLabels(csv_file=train_csv, image_folder=train_image_folder, transform=train_transforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WLczoprf9BBS"
   },
   "outputs": [],
   "source": [
    "# Defining a function to split data into train and test sets\n",
    "def split_data(data,ratio=0.8):\n",
    "    train_size = int(ratio * len(data))\n",
    "    test_size = len(data) - train_size\n",
    "    train_data, test_data = random_split(data, [train_size, test_size])\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "3Zqbqg4G9CLy"
   },
   "outputs": [],
   "source": [
    "# Defining a function to define data loaders\n",
    "# Found batch size 128 to be the optimal value based on testing\n",
    "def create_dataloaders(train_data, test_data,b_train=128,b_test=32):\n",
    "    train_loader = DataLoader(train_data, batch_size=b_train, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=b_test, shuffle=False)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train and test sets\n",
    "train_loader, test_loader = create_dataloaders(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "Cr5HHGHtSzS8"
   },
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "from torchvision.models import resnet18\n",
    "model = resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs,2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "SESFpj7B9a21"
   },
   "outputs": [],
   "source": [
    "# Define the optimizer and scehduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PrJSOIR9mAh",
    "outputId": "5a1a6296-fb17-4095-8cbe-4b76e36a9d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.2652, Accuracy: 91.49%\n",
      "Epoch 2/40, Loss: 0.1356, Accuracy: 94.84%\n",
      "Epoch 3/40, Loss: 0.0819, Accuracy: 97.08%\n",
      "Epoch 4/40, Loss: 0.0669, Accuracy: 97.45%\n",
      "Epoch 5/40, Loss: 0.0503, Accuracy: 97.93%\n",
      "Epoch 6/40, Loss: 0.0474, Accuracy: 98.06%\n",
      "Epoch 7/40, Loss: 0.0604, Accuracy: 97.81%\n",
      "Epoch 8/40, Loss: 0.0413, Accuracy: 98.60%\n",
      "Epoch 9/40, Loss: 0.0415, Accuracy: 98.48%\n",
      "Epoch 10/40, Loss: 0.0265, Accuracy: 99.21%\n",
      "Epoch 11/40, Loss: 0.0240, Accuracy: 98.91%\n",
      "Epoch 12/40, Loss: 0.0124, Accuracy: 99.39%\n",
      "Epoch 13/40, Loss: 0.0089, Accuracy: 99.70%\n",
      "Epoch 14/40, Loss: 0.0090, Accuracy: 99.64%\n",
      "Epoch 15/40, Loss: 0.0089, Accuracy: 99.51%\n",
      "Epoch 16/40, Loss: 0.0056, Accuracy: 99.94%\n",
      "Epoch 17/40, Loss: 0.0068, Accuracy: 99.70%\n",
      "Epoch 18/40, Loss: 0.0071, Accuracy: 99.64%\n",
      "Epoch 19/40, Loss: 0.0057, Accuracy: 99.76%\n",
      "Epoch 20/40, Loss: 0.0054, Accuracy: 99.76%\n",
      "Epoch 21/40, Loss: 0.0054, Accuracy: 99.64%\n",
      "Epoch 22/40, Loss: 0.0052, Accuracy: 99.70%\n",
      "Epoch 23/40, Loss: 0.0057, Accuracy: 99.64%\n",
      "Epoch 24/40, Loss: 0.0050, Accuracy: 99.82%\n",
      "Epoch 25/40, Loss: 0.0053, Accuracy: 99.82%\n",
      "Epoch 26/40, Loss: 0.0062, Accuracy: 99.76%\n",
      "Epoch 27/40, Loss: 0.0051, Accuracy: 99.82%\n",
      "Epoch 28/40, Loss: 0.0048, Accuracy: 99.76%\n",
      "Epoch 29/40, Loss: 0.0044, Accuracy: 99.88%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhew6HeN9pHI",
    "outputId": "2e2289be-f363-4088-f03a-c80401789113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.58%\n"
     ]
    }
   ],
   "source": [
    "# Used to evaluate test data if data is split into train and test\n",
    "def evaluate_test(test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "IX7OuBETCk2g"
   },
   "outputs": [],
   "source": [
    "# Define a function to predict the outputs for test data\n",
    "results = {}\n",
    "def predict_op():\n",
    "  global res\n",
    "  global results\n",
    "  res[\"emergency_or_not\"].clear()\n",
    "  model.eval()\n",
    "  test_correct = 0\n",
    "  test_total = 0\n",
    "  with torch.no_grad():\n",
    "      for inputs in test_loader_temp:\n",
    "          inputs = inputs.to(device)\n",
    "\n",
    "          outputs = model(inputs)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          # print([t.item() for t in list(predicted)])\n",
    "          res[\"emergency_or_not\"].extend([t.item() for t in list(predicted)])\n",
    "  results = {}\n",
    "  for i in range(len(res[\"image_names\"])):\n",
    "    results[res[\"image_names\"][i]] = res[\"emergency_or_not\"][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "zhVcAV7eCqAB"
   },
   "outputs": [],
   "source": [
    "# Define a function to create csv\n",
    "def create_csv(name):\n",
    "  temp = []\n",
    "  import pandas as pd\n",
    "  data = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
    "  for i in list(data[\"image_names\"]):\n",
    "    temp.append(results[i])\n",
    "  data[\"emergency_or_not\"] = temp\n",
    "  data.to_csv(f\"{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the outputs and create the final csv file\n",
    "predict_op()\n",
    "create_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1hnIhy59dPo"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
