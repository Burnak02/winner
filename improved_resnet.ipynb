{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7UlbYJaSIeO",
        "outputId": "752ede87-cad4-431e-fdf7-bb1f0ba241b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "#import torch libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repo\n",
        "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NhhI4TLSoxh",
        "outputId": "3d095f41-afa0-4a65-814d-fb6cea84bafc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Qualcomm-DL-Hackathon'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 30.68 MiB | 14.90 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the content\n",
        "extract_dir = \"/content/Train\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "#open and extract the zip file\n",
        "for i in range(1,3):\n",
        "  with zipfile.ZipFile(f\"/content/Qualcomm-DL-Hackathon/train/images part-{i}.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "RJ9QYzaSSsV9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_csv = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/train/train.csv\")\n",
        "test = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")"
      ],
      "metadata": {
        "id": "KjanpXuTTON-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract images and split them into train and test\n",
        "\n",
        "destination_folder = \"/content/Train/train_images\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "  os.makedirs(destination_folder)\n",
        "\n",
        "for i in range(1,3):\n",
        "  source_folder = f\"/content/Train/images part-{i}\"\n",
        "  for root, dirs, files in os.walk(source_folder):\n",
        "    for file in files:\n",
        "      src_file = os.path.join(root, file)\n",
        "      shutil.copy2(src_file, destination_folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "JZrjbCXGS24H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting datasets into train and test\n",
        "test_images = list(test[\"image_names\"])\n",
        "source_folder = f\"/content/Train/train_images\"\n",
        "destination_folder = \"/content/Train/final_test_images\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "  os.makedirs(destination_folder)\n",
        "count = 0\n",
        "for root, dirs, files in os.walk(source_folder):\n",
        "  for file in files:\n",
        "    # if count < 1:\n",
        "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
        "    count += 1\n",
        "    if file in test_images:\n",
        "      # print(\"file\")\n",
        "      src_file = os.path.join(root, file)\n",
        "      shutil.move(src_file, destination_folder)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbKZpbUGTI_G",
        "outputId": "4a565f62-15b9-46c6-f5b1-38814e2ca922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the res dict to construct final csv at the end\n",
        "count = 0\n",
        "res = {\"image_names\":[], \"emergency_or_not\":[]}\n",
        "for root, dirs, files in os.walk(destination_folder):\n",
        "  for file in files:\n",
        "    # if count < 1:\n",
        "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
        "    count += 1\n",
        "    res[\"image_names\"].append(file)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L26HTJhdTdn1",
        "outputId": "ca29ee79-90b2-4795-ecdb-56e1802e0b9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a class to handle image to label mapping with(for train) and without labels(for test)\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CustomImageDatasetWithLabels(Dataset):\n",
        "    def __init__(self, csv_file, image_folder, transform=None):\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.labels_df.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        label = int(self.labels_df.iloc[idx, 1])  # Convert label to int\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "class CustomImageDatasetWithoutLabels(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_names = os.listdir(image_folder)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.image_names[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "c_DlI-7ATtQd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definie the train and test transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomRotation(20),  # Randomly rotate images by up to 20 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomVerticalFlip(),  # Randomly flip images vertically\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change brightness, contrast, saturation, and hue\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Randomly translate images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "wPLerkBSUrSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "XEiDiMhKALr_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paths to your CSV files and image folders\n",
        "train_csv = '/content/Qualcomm-DL-Hackathon/train/train.csv'\n",
        "train_image_folder = '/content/Train/train_images'\n",
        "\n",
        "# Initialize your datasets\n",
        "train_dataset = CustomImageDatasetWithLabels(csv_file=train_csv, image_folder=train_image_folder, transform=train_transforms)\n",
        "\n"
      ],
      "metadata": {
        "id": "KwhUtoO1U9H1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "test_size = len(train_dataset) - train_size\n",
        "train_data, test_data = random_split(train_dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "WLczoprf9BBS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "3Zqbqg4G9CLy"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "from torchvision.models import resnet18\n",
        "model = resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs,2)\n",
        "\n",
        "model = model.to(device)\n",
        "# # Set requires_grad=True for all parameters\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# # Continue as usual\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Sequential(\n",
        "#     nn.Dropout(0.5),\n",
        "#     nn.Linear(num_ftrs, 2)\n",
        "# )\n",
        "\n",
        "# model = model.to(device)\n"
      ],
      "metadata": {
        "id": "ShkaC_789GOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a17ec6-afb4-4671-b4ab-0321a63f50b1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.models import resnet18\n",
        "\n",
        "# model = resnet18(pretrained=True)\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Sequential(\n",
        "#     nn.Dropout(0.5),\n",
        "#     nn.Linear(num_ftrs, 2)\n",
        "# )\n",
        "\n",
        "# model = model.to(device)\n"
      ],
      "metadata": {
        "id": "Cr5HHGHtSzS8"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer and scehduler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "SESFpj7B9a21"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 40\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "    # if (epoch+1) % 10 == 0:\n",
        "    #   predict_op()\n",
        "    #   create_csv(f\"resnet50_epoch_{epoch+1}\")\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PrJSOIR9mAh",
        "outputId": "5a1a6296-fb17-4095-8cbe-4b76e36a9d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40, Loss: 0.2652, Accuracy: 91.49%\n",
            "Epoch 2/40, Loss: 0.1356, Accuracy: 94.84%\n",
            "Epoch 3/40, Loss: 0.0819, Accuracy: 97.08%\n",
            "Epoch 4/40, Loss: 0.0669, Accuracy: 97.45%\n",
            "Epoch 5/40, Loss: 0.0503, Accuracy: 97.93%\n",
            "Epoch 6/40, Loss: 0.0474, Accuracy: 98.06%\n",
            "Epoch 7/40, Loss: 0.0604, Accuracy: 97.81%\n",
            "Epoch 8/40, Loss: 0.0413, Accuracy: 98.60%\n",
            "Epoch 9/40, Loss: 0.0415, Accuracy: 98.48%\n",
            "Epoch 10/40, Loss: 0.0265, Accuracy: 99.21%\n",
            "Epoch 11/40, Loss: 0.0240, Accuracy: 98.91%\n",
            "Epoch 12/40, Loss: 0.0124, Accuracy: 99.39%\n",
            "Epoch 13/40, Loss: 0.0089, Accuracy: 99.70%\n",
            "Epoch 14/40, Loss: 0.0090, Accuracy: 99.64%\n",
            "Epoch 15/40, Loss: 0.0089, Accuracy: 99.51%\n",
            "Epoch 16/40, Loss: 0.0056, Accuracy: 99.94%\n",
            "Epoch 17/40, Loss: 0.0068, Accuracy: 99.70%\n",
            "Epoch 18/40, Loss: 0.0071, Accuracy: 99.64%\n",
            "Epoch 19/40, Loss: 0.0057, Accuracy: 99.76%\n",
            "Epoch 20/40, Loss: 0.0054, Accuracy: 99.76%\n",
            "Epoch 21/40, Loss: 0.0054, Accuracy: 99.64%\n",
            "Epoch 22/40, Loss: 0.0052, Accuracy: 99.70%\n",
            "Epoch 23/40, Loss: 0.0057, Accuracy: 99.64%\n",
            "Epoch 24/40, Loss: 0.0050, Accuracy: 99.82%\n",
            "Epoch 25/40, Loss: 0.0053, Accuracy: 99.82%\n",
            "Epoch 26/40, Loss: 0.0062, Accuracy: 99.76%\n",
            "Epoch 27/40, Loss: 0.0051, Accuracy: 99.82%\n",
            "Epoch 28/40, Loss: 0.0048, Accuracy: 99.76%\n",
            "Epoch 29/40, Loss: 0.0044, Accuracy: 99.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "test_size = len(train_dataset) - train_size\n",
        "train_data , test_data = random_split(train_dataset, [train_size, test_size])\n",
        "test_loader_temp = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "G_ayG93tEL6S"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhew6HeN9pHI",
        "outputId": "2e2289be-f363-4088-f03a-c80401789113"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your test dataset\n",
        "test_dataset = CustomImageDatasetWithoutLabels(image_folder='/content/Train/final_test_images', transform=test_transforms)\n",
        "test_loader_temp = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "-Lq_nIW9BjqQ"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K3fTlZFELU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[\"emergency_or_not\"].clear()\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs in test_loader_temp:\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print([t.item() for t in list(predicted)])\n",
        "        res[\"emergency_or_not\"].extend([t.item() for t in list(predicted)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvTOZmpZBYlS",
        "outputId": "fa991549-86d5-4282-8365-fd6dbaa9a5f7"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0]\n",
            "[1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1]\n",
            "[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
            "[0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0]\n",
            "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1]\n",
            "[0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
            "[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "[0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(res[\"emergency_or_not\"]), len(res[\"image_names\"]))\n",
        "results = {}\n",
        "for i in range(len(res[\"image_names\"])):\n",
        "  results[res[\"image_names\"][i]] = res[\"emergency_or_not\"][i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE7HJQRiBypd",
        "outputId": "ef47ef8f-e045-483a-ac00-0cf20f430ff7"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706 706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = []\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
        "for i in list(data[\"image_names\"]):\n",
        "  temp.append(results[i])\n",
        "data[\"emergency_or_not\"] = temp\n",
        "data.to_csv(\"submission_e_30.csv\", index=False)"
      ],
      "metadata": {
        "id": "o_RXUCxsB1dE"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "def predict_op():\n",
        "  global res\n",
        "  global results\n",
        "  res[\"emergency_or_not\"].clear()\n",
        "  model.eval()\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  with torch.no_grad():\n",
        "      for inputs in test_loader_temp:\n",
        "          inputs = inputs.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          # print([t.item() for t in list(predicted)])\n",
        "          res[\"emergency_or_not\"].extend([t.item() for t in list(predicted)])\n",
        "  results = {}\n",
        "  for i in range(len(res[\"image_names\"])):\n",
        "    results[res[\"image_names\"][i]] = res[\"emergency_or_not\"][i]\n"
      ],
      "metadata": {
        "id": "IX7OuBETCk2g"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_csv(name):\n",
        "  temp = []\n",
        "  import pandas as pd\n",
        "  data = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
        "  for i in list(data[\"image_names\"]):\n",
        "    temp.append(results[i])\n",
        "  data[\"emergency_or_not\"] = temp\n",
        "  data.to_csv(f\"{name}.csv\", index=False)"
      ],
      "metadata": {
        "id": "zhVcAV7eCqAB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W1hnIhy59dPo"
      }
    }
  ]
}