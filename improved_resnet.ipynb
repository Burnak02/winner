{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7UlbYJaSIeO",
        "outputId": "752ede87-cad4-431e-fdf7-bb1f0ba241b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "#import torch libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repo\n",
        "!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NhhI4TLSoxh",
        "outputId": "3d095f41-afa0-4a65-814d-fb6cea84bafc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Qualcomm-DL-Hackathon'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 30.68 MiB | 14.90 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the content\n",
        "extract_dir = \"/content/Train\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "#open and extract the zip file\n",
        "for i in range(1,3):\n",
        "  with zipfile.ZipFile(f\"/content/Qualcomm-DL-Hackathon/train/images part-{i}.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "RJ9QYzaSSsV9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_csv = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/train/train.csv\")\n",
        "test = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")"
      ],
      "metadata": {
        "id": "KjanpXuTTON-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract images and split them into train and test\n",
        "\n",
        "destination_folder = \"/content/Train/train_images\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "  os.makedirs(destination_folder)\n",
        "\n",
        "for i in range(1,3):\n",
        "  source_folder = f\"/content/Train/images part-{i}\"\n",
        "  for root, dirs, files in os.walk(source_folder):\n",
        "    for file in files:\n",
        "      src_file = os.path.join(root, file)\n",
        "      shutil.copy2(src_file, destination_folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "JZrjbCXGS24H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting datasets into train and test\n",
        "test_images = list(test[\"image_names\"])\n",
        "source_folder = f\"/content/Train/train_images\"\n",
        "destination_folder = \"/content/Train/final_test_images\"\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "  os.makedirs(destination_folder)\n",
        "count = 0\n",
        "for root, dirs, files in os.walk(source_folder):\n",
        "  for file in files:\n",
        "    # if count < 1:\n",
        "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
        "    count += 1\n",
        "    if file in test_images:\n",
        "      # print(\"file\")\n",
        "      src_file = os.path.join(root, file)\n",
        "      shutil.move(src_file, destination_folder)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbKZpbUGTI_G",
        "outputId": "4a565f62-15b9-46c6-f5b1-38814e2ca922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the res dict to construct final csv at the end\n",
        "count = 0\n",
        "res = {\"image_names\":[], \"emergency_or_not\":[]}\n",
        "for root, dirs, files in os.walk(destination_folder):\n",
        "  for file in files:\n",
        "    # if count < 1:\n",
        "    #   print(file, type(file), test_images[0],type(test_images[0]))\n",
        "    count += 1\n",
        "    res[\"image_names\"].append(file)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L26HTJhdTdn1",
        "outputId": "ca29ee79-90b2-4795-ecdb-56e1802e0b9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a class to handle image to label mapping with(for train) and without labels(for test)\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CustomImageDatasetWithLabels(Dataset):\n",
        "    def __init__(self, csv_file, image_folder, transform=None):\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.labels_df.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        label = int(self.labels_df.iloc[idx, 1])  # Convert label to int\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "class CustomImageDatasetWithoutLabels(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_names = os.listdir(image_folder)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.image_names[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "c_DlI-7ATtQd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definie the train and test transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomRotation(20),  # Randomly rotate images by up to 20 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomVerticalFlip(),  # Randomly flip images vertically\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change brightness, contrast, saturation, and hue\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Randomly translate images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "wPLerkBSUrSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "XEiDiMhKALr_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paths to your CSV files and image folders\n",
        "train_csv = '/content/Qualcomm-DL-Hackathon/train/train.csv'\n",
        "train_image_folder = '/content/Train/train_images'\n",
        "\n",
        "# Initialize your datasets\n",
        "train_dataset = CustomImageDatasetWithLabels(csv_file=train_csv, image_folder=train_image_folder, transform=train_transforms)\n",
        "\n"
      ],
      "metadata": {
        "id": "KwhUtoO1U9H1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "test_size = len(train_dataset) - train_size\n",
        "train_data, test_data = random_split(train_dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "WLczoprf9BBS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "3Zqbqg4G9CLy"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "from torchvision.models import resnet18\n",
        "model = resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs,2)\n",
        "\n",
        "model = model.to(device)\n",
        "# # Set requires_grad=True for all parameters\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# # Continue as usual\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Sequential(\n",
        "#     nn.Dropout(0.5),\n",
        "#     nn.Linear(num_ftrs, 2)\n",
        "# )\n",
        "\n",
        "# model = model.to(device)\n"
      ],
      "metadata": {
        "id": "ShkaC_789GOa",
        "outputId": "177eacbf-c9a7-4305-eb8a-132b3c8d9a0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.models import resnet18\n",
        "\n",
        "# model = resnet18(pretrained=True)\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Sequential(\n",
        "#     nn.Dropout(0.5),\n",
        "#     nn.Linear(num_ftrs, 2)\n",
        "# )\n",
        "\n",
        "# model = model.to(device)\n"
      ],
      "metadata": {
        "id": "Cr5HHGHtSzS8"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer and scehduler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "SESFpj7B9a21"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "    # if (epoch+1) % 10 == 0:\n",
        "    #   predict_op()\n",
        "    #   create_csv(f\"resnet50_epoch_{epoch+1}\")\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PrJSOIR9mAh",
        "outputId": "f22b6288-08c6-4cdb-ba79-100ae6dc81ef"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.0156, Accuracy: 99.47%\n",
            "Epoch 2/5, Loss: 0.0100, Accuracy: 99.92%\n",
            "Epoch 3/5, Loss: 0.0154, Accuracy: 99.70%\n",
            "Epoch 4/5, Loss: 0.0133, Accuracy: 99.85%\n",
            "Epoch 5/5, Loss: 0.0160, Accuracy: 99.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "test_size = len(train_dataset) - train_size\n",
        "train_data , test_data = random_split(train_dataset, [train_size, test_size])\n",
        "test_loader_temp = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "G_ayG93tEL6S"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhew6HeN9pHI",
        "outputId": "bb8a6912-3075-40fe-9c75-b7c248515d8f"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your test dataset\n",
        "test_dataset = CustomImageDatasetWithoutLabels(image_folder='/content/Train/final_test_images', transform=test_transforms)\n",
        "test_loader_temp = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "-Lq_nIW9BjqQ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K3fTlZFELU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[\"emergency_or_not\"].clear()\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs in test_loader_temp:\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print([t.item() for t in list(predicted)])\n",
        "        res[\"emergency_or_not\"].extend([t.item() for t in list(predicted)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvTOZmpZBYlS",
        "outputId": "33a18c63-d602-4f0b-d15e-3951fea443ff"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "[1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0]\n",
            "[1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1]\n",
            "[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
            "[1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
            "[0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
            "[0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0]\n",
            "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
            "[0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
            "[1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1]\n",
            "[0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
            "[1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
            "[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "[0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(res[\"emergency_or_not\"]), len(res[\"image_names\"]))\n",
        "results = {}\n",
        "for i in range(len(res[\"image_names\"])):\n",
        "  results[res[\"image_names\"][i]] = res[\"emergency_or_not\"][i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE7HJQRiBypd",
        "outputId": "fd1aec3c-d7cf-4d68-992e-274c9d4adbc9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706 706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = []\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
        "for i in list(data[\"image_names\"]):\n",
        "  temp.append(results[i])\n",
        "data[\"emergency_or_not\"] = temp\n",
        "data.to_csv(\"submission_e_35.csv\", index=False)"
      ],
      "metadata": {
        "id": "o_RXUCxsB1dE"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "def predict_op():\n",
        "  global res\n",
        "  global results\n",
        "  res[\"emergency_or_not\"].clear()\n",
        "  model.eval()\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  with torch.no_grad():\n",
        "      for inputs in test_loader_temp:\n",
        "          inputs = inputs.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          # print([t.item() for t in list(predicted)])\n",
        "          res[\"emergency_or_not\"].extend([t.item() for t in list(predicted)])\n",
        "  results = {}\n",
        "  for i in range(len(res[\"image_names\"])):\n",
        "    results[res[\"image_names\"][i]] = res[\"emergency_or_not\"][i]\n"
      ],
      "metadata": {
        "id": "IX7OuBETCk2g"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_csv(name):\n",
        "  temp = []\n",
        "  import pandas as pd\n",
        "  data = pd.read_csv(\"/content/Qualcomm-DL-Hackathon/test.csv\")\n",
        "  for i in list(data[\"image_names\"]):\n",
        "    temp.append(results[i])\n",
        "  data[\"emergency_or_not\"] = temp\n",
        "  data.to_csv(f\"{name}.csv\", index=False)"
      ],
      "metadata": {
        "id": "zhVcAV7eCqAB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W1hnIhy59dPo"
      }
    }
  ]
}